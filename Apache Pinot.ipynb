{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "standing-yeast",
   "metadata": {},
   "source": [
    "# Apache Pinot\n",
    "\n",
    "_Seminararbeit von Nikola Braukm√ºller (1424783) und Tim Ebert (8559152) zum Modul \"Advanced Data Management\" (W3M20011) am DHBW CAS (WiSe 2020/21)._  \n",
    "_Abgabedatum: 12. April 2021_  \n",
    "_Dozent: Prof. Dr. Dennis Pfisterer_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-costume",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-benchmark",
   "metadata": {},
   "source": [
    "## Install Pinot on Kubernetes Cluster\n",
    "\n",
    "To install a simple Pinot setup including 3 servers and a miminal Kafka cluster on a Kubernetes cluster, follow these steps.\n",
    "In our tests we used a single-node cluster on GCP with 4 CPUs and 16 GB of Memory (instance type `n1-standard-4`). We observed that this machine was well utilized during data ingestion, so we recommend using a similarly sized cluster.  \n",
    "See [values.yaml](https://github.com/timebertt/adm-pinot/blob/master/pinot/values.yaml) for further configuration options, e.g. to configure a faster storage class for Pinot's PVCs (we used SSDs (`pd-ssd`) in our tests for better performance).\n",
    "\n",
    "```bash\n",
    "# create and switch to pinot namespace\n",
    "kubectl create namespace pinot\n",
    "kubectl config set-context --current --namespace pinot\n",
    "\n",
    "# install our pre-built helm chart in pinot namespace using the default configuration\n",
    "helm install pinot https://raw.githubusercontent.com/timebertt/adm-pinot/master/assets/pinot-0.1.0.tgz\n",
    "\n",
    "# wait until all pinot components are ready\n",
    "kubectl get pod -w\n",
    "```\n",
    "\n",
    "Once all components are ready, you can open the Pinot dashboard to see if everything is working as expected.\n",
    "```\n",
    "kubectl port-forward svc/pinot-controller 9000 &\n",
    "```\n",
    "Navigate to http://localhost:9000/ to open the Pinot dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-multiple",
   "metadata": {},
   "source": [
    "## Python requirements\n",
    "\n",
    "Install the Python modules required by this Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -I 'kafka-python==2.0.2' 'names==0.3.0' 'pandas==1.2.3' 'requests==2.25.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "defined-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import copy, requests, json, io, re, os, shutil, fileinput, tarfile, time, csv, random, names\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-district",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-april",
   "metadata": {},
   "source": [
    "Pinot is an open-source distributed highly-available OLAP datastore and built to serve analytical queries on realtime event data. It is developed by engineers of LinkedIn and Uber.\n",
    "LinkedIn is operating Pinot clusters for realtime Online Analytical Processing. They divide their analytics applications into two main categories in their solution landscape: Internal applications and user-facing applications. Internal applications need to process large data volume (trillions of records), but higher query latencies are tolerated. On the opposite, user-facing applications are available for hundreds of millions of LinkedIn members. These applications have a very high query volume and are expected to have a lower latency.\n",
    "Pinot production clusters at LinkedIn are serving tens of thousands queries per second. Overall, more than 50 analytical use cases are supported, and millions of records are ingested per second."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-tackle",
   "metadata": {},
   "source": [
    "## Design Principles\n",
    "\n",
    "Key requirements for Pinot include:\n",
    "\n",
    "- high performance (low latency) query execution\n",
    "- near-realtime data ingestion\n",
    "- linear horizontal scalability (in terms of data size, ingestion rate and query rate)\n",
    "- query flexibility to cover a wide range of analytical use cases\n",
    "- high availability of data as well as components (fault tolerance)\n",
    "\n",
    "All of these requirements influence Pinot's fundamental design principles and distributed architecture. We present, how Pinot manages to achieve these goals in the following sections by describing the core concepts and demonstrating the most important mechanisms in Pinot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-noise",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "A Pinot cluster is comprised of multiple distributed components. Each Pinot cluster consists of a controller, one or multiple brokers and multiple servers. Pinot supports multi-tenancy out-of-the-box, as multiple brokers and servers can be assigned to serve specific tenants. A table in pinot consists of columns and rows, which are broken horizontally into shards (named segments).\n",
    "\n",
    "Apache Helix is a generic cluster management framework which is used for automatic management of partitioned and replicated distributed systems by creating and assigning tasks. Apache Zookeeper takes care of coordination and maintenance of the overall cluster state and health. In addition, it stores information about the cluster like server locations of a segment and table schema information. The Controller embeds the Helix agent and is the driver of the cluster. To access CRUD (Create, Read, Update, Delete) Operations on logical storage resources, it provides a REST interface.\n",
    "\n",
    "If a client wants to query data of Pinot tables, the request will be sent to the broker. It routes queries to the appropriate server instances and keeps track on the query routing tables. These routing tables consist of a mapping between segments and server, where the segments reside on. This ensures the right routing of the query to the correct segment. Segments can either consume realtime data or data can be pushed into offline segments. By default, the query load is balanced across all available servers. The broker will return one consolidated result to the client, independent from the fact whether the table is divided into realtime and offline segments.\n",
    "\n",
    "Servers are categorized into offline and realtime servers. According to this categorization, servers in Pinot either host offline or realtime data. The responsibility of a server is defined by the table assignment strategy.\n",
    "\n",
    "If a new realtime table is configured, the realtime server will start consuming data from the streaming source (e.g. Kafka topic). The broker will watch the consumption, detect new segments and maintain them in the query routing list. If a segment has been completed (reached a specific amount of records or was available for a specific timeframe), the controller will upload the segment to the cluster's segment store. The status of the uploaded segment changes from \"consuming\" to \"online\" and the controller will start a new consumption on the realtime server.\n",
    "With batch ingestion, already existing data (e.g. in Hadoop) can be loaded to a Pinot table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-dublin",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/timebertt/adm-pinot/master/images/Architecture.png' width=\"35%\" height=\"35%\">\n",
    "                                                 \n",
    "Image source: https://docs.pinot.apache.org/basics/architecture (accessed April, 4th 2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-behavior",
   "metadata": {},
   "source": [
    "In addition to components shown in the above architectural diagram, minions can be deployed to the cluster. They leverage Apache Helix and execute tasks which are provided by the Helix Task Executor Framwork. A minion takes over tasks with intensive workloads from other components like indexing or purging data from a Pinot cluster, for example due to GDPR compliance.\n",
    "The Pinot minion can also be used for Pinot's Offline Flow, which moves records from `REALTIME` tables to corresponding `OFFLINE` tables (covered later on)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-friendship",
   "metadata": {},
   "source": [
    "## API Interface for Broker and Controller\n",
    "\n",
    "Queries are sent to the broker's REST API (listening on port 8099 by default).\n",
    "To get information about the resources of the Pinot cluster, we are accessing the controller's REST API, which is listening on port 9000.\n",
    "Broker Configurations are defined in a specific `broker.conf` file. The properties define configurations like the query port for the broker or a limit for queries. The latter of which has the purpose to protect brokers and servers against queries returning very large amount of records. A query limit needs to be enabled at cluster level. In our scenario, the parameter `pinot.broker.enable.query.limit.override` is set to false, which means that the broker won't override or add a query limit when the returned record amount is larger than defined in the broker config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "atomic-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBroker: \u001b[0m{\n",
      "  \"DefaultTenant\": [\n",
      "    {\n",
      "      \"host\": \"Broker_pinot-broker-0.pinot-broker-headless.pinot.svc.cluster.local\",\n",
      "      \"port\": 8099,\n",
      "      \"instanceName\": \"Broker_pinot-broker-0.pinot-broker-headless.pinot.svc.cluster.local_8099\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[1mHealth of Controller: \u001b[0mGOOD\n",
      "\u001b[1mCluster: \u001b[0m{\n",
      "  \"allowParticipantAutoJoin\": \"true\",\n",
      "  \"enable.case.insensitive\": \"false\",\n",
      "  \"pinot.broker.enable.query.limit.override\": \"false\",\n",
      "  \"default.hyperloglog.log2m\": \"8\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[1m\" + \"Broker: \"+ \"\\033[0m\" + json.dumps((requests.get('http://pinot-controller.pinot:9000/v2/brokers/tenants')).json(), indent=2))\n",
    "print(\"\\033[1m\" + \"Health of Controller: \"+ \"\\033[0m\" + requests.get('http://pinot-controller.pinot:9000/pinot-controller/admin').text)\n",
    "print(\"\\033[1m\" + \"Cluster: \"+ \"\\033[0m\" + json.dumps((requests.get('http://pinot-controller.pinot:9000/cluster/configs')).json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-immigration",
   "metadata": {},
   "source": [
    "## Key differences to well-known database technologies\n",
    "\n",
    "In Pinot, data ingestion is append-only. There is no possibility to modify values after ingestion by doing operations like `UPDATE` known from databases like PostgreSQL. Pinot is no replacement for databases in an operational business environment, which usually require updates to data because of the event's nature or due to data correction. For this use cases, Pinot does not fit. Instead, it can enhance use cases requiring fast analytics. However, data can still be purged after ingestion for fullfilling compliance requirements (e.g. GDPR). For this, the Minion can be used to replace entire segments, but in no case, single records can be manipulated.\n",
    "\n",
    "Another difference of Apache Pinot compared to databases like PostgreSQL is that it doesn't support queries requiring movements of large amounts of data between the nodes, like joins. The query engine Presto can be used to join different tables in Pinot, but Presto needs to be set up additionally and is not part of Pinot.\n",
    "\n",
    "Tables in Pinot typically have one primary time column, which is used to manage the time boundary between offline and realtime data in a hybrid table. This may sound familiar to the known concept of time series databases like Influxdb. Both databases are built to handle events with a timestamp, but the timestamp in Pinot is only strictly required for hybrid tables. In addition, Pinot is not only focused on storing timeseries of metrics, it also offers to storm string and bytes values in addition to numeric data types and date time fields. Although Influxdb also support strings to a specific extend, Pinot also offers e.g. text indexing for enhanced full text search.\n",
    "Compared to the timeseries databases like Influxdb, Pinot is optimized for storing time data with a focus on append operations and queries. Update and delete operations on single records are not supported in Apache Pinot, though stream ingestion supports upserts, if a primary key has been defined in the schema.\n",
    "\n",
    "Another key difference of Pinot in comparison to other distributed databases is the heterogeneous nature of its components. Some traditional RDBMSs like for example PostgreSQL can be scaled horizontally to form a cluster by adding more instances, that will each store and manage different partitions (shards) of the dataset. In this case, such a distributed setup is comprised of only a single stateful component, which is started on multiple machines (homogeneous distributed system).\n",
    "In contrast to this, a Pinot cluster is comprised of multiple heterogeneous components (described above), which each serve a specific purpose and are only responsible for a given subtask of the entire system. For example, servers are the stateful components of Pinot, that store and query the actual dataset, while brokers are stateless components, that don't host data themselves and only serve the query frontend for the database. With this, Pinot can be seen as a heterogeneous distributed system, which makes it more complex to deploy and operate, but also serves the key requirements described above (mainly horizontal scalability and fault tolerance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-wallet",
   "metadata": {},
   "source": [
    "## Schemas and Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-distributor",
   "metadata": {},
   "source": [
    "### Schemas\n",
    "\n",
    "To create a table in Pinot, a schema is required. A schema configuration defines fields and data types, this metadata is stored in the Zookeeper.\n",
    "In our examples, we work with data of a fictional online plattform which connects car drivers and passengers to travel together in Germany (ride sharing). \n",
    "\n",
    "Columns in Pinot are of different categories: \n",
    "- dimension columns: support operations like `GROUP BY` and `WHERE` (\"slice and dice\"), e.g. name of the car driver, trip start and end location\n",
    "- metric columns: represent quantitative data and can be used e.g. for aggregation clauses (e.g. payment amount, rating of the driver)\n",
    "- DateTime columns: represent timestamps of records. One DataTime column can be treated as the primary time column, which is defined in the segment config of a table. The primary time column is used for determining boundaries of segments and between offline and realtime data in hybrid tables. A typical operation on DateTime columns is for example `WHERE`, e.g. to select rides of a given day\n",
    "\n",
    "Let's define the example `trips` schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acceptable-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Schema: {\"status\":\"trips successfully added\"}\n",
      "Get all schemas: ['trips']\n"
     ]
    }
   ],
   "source": [
    "schemaConfiguration = {\n",
    "  \"schemaName\": \"trips\",\n",
    "  \"dimensionFieldSpecs\": [\n",
    "    {\n",
    "      \"name\": \"rider_name\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"driver_name\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"license_plate\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"start_location\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"start_zip_code\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    },\n",
    "     {\n",
    "      \"name\": \"start_location_state\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    }, \n",
    "    {\n",
    "      \"name\": \"end_location\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"end_zip_code\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    },\n",
    "      {\n",
    "      \"name\": \"end_location_state\",\n",
    "      \"dataType\": \"STRING\",\n",
    "      \"defaultNullValue\": \"\"\n",
    "    }, \n",
    "    {\n",
    "      \"name\": \"rider_is_premium\",\n",
    "      \"dataType\": \"INT\",\n",
    "      \"defaultNullValue\": 0\n",
    "    }\n",
    "  ],\n",
    "  \"metricFieldSpecs\": [\n",
    "    {\n",
    "      \"name\": \"count\",\n",
    "      \"dataType\": \"LONG\",\n",
    "      \"defaultNullValue\": 1\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"payment_amount\",\n",
    "      \"dataType\": \"FLOAT\",\n",
    "      \"defaultNullValue\": 0\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"payment_tip_amount\",\n",
    "      \"dataType\": \"FLOAT\",\n",
    "      \"defaultNullValue\": 0\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"trip_wait_time_millis\",\n",
    "      \"dataType\": \"LONG\",\n",
    "      \"defaultNullValue\": 0\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"rider_rating\",\n",
    "      \"dataType\": \"INT\",\n",
    "      \"defaultNullValue\": 0\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"driver_rating\",\n",
    "      \"dataType\": \"INT\",\n",
    "      \"defaultNullValue\": 0\n",
    "    }\n",
    "  ],\n",
    "  \"dateTimeFieldSpecs\": [\n",
    "    {\n",
    "      \"name\": \"trip_start_time_millis\",\n",
    "      \"dataType\": \"LONG\",\n",
    "      \"format\": \"1:MILLISECONDS:EPOCH\",\n",
    "      \"granularity\": \"1:MINUTES\",\n",
    "      \"dateTimeType\": \"PRIMARY\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"request_time_millis\",\n",
    "      \"dataType\": \"LONG\",\n",
    "      \"format\": \"1:MILLISECONDS:EPOCH\",\n",
    "      \"granularity\": \"1:MINUTES\",\n",
    "      \"dateTimeType\": \"SECONDARY\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"trip_end_time_millis\",\n",
    "      \"dataType\": \"LONG\",\n",
    "      \"format\": \"1:MILLISECONDS:EPOCH\",\n",
    "      \"granularity\": \"1:MINUTES\",\n",
    "      \"dateTimeType\": \"SECONDARY\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "# create the trips schema\n",
    "response = requests.post('http://pinot-controller.pinot:9000/schemas?override=true', json=schemaConfiguration)\n",
    "print(\"Create Schema: \" + response.text)\n",
    "\n",
    "# list all Schemas\n",
    "response = (requests.get('http://pinot-controller.pinot:9000/schemas')).json()\n",
    "print(\"Get all schemas: \" + str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-decision",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "\n",
    "Our Pinot tables will consume data from a Kafka Topic in realtime. To be able to consume messages from this topic, data needs to be produced and sent to the topic before.\n",
    "\n",
    "To create and fill our Kafka topic, we first need to create a Kafka producer client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nearby-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=['pinot-kafka.pinot:9092'], value_serializer=lambda v: json.dumps(v).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-matter",
   "metadata": {},
   "source": [
    "The below functions are used to generate random data records for car rides in Germany and inserts them to the Kafka Topic. Each ride consists of driver and passenger details, such as name and rating, measures like payments, details about origin and destination of the trip and different time measures, for example the time stamp when the trip was requested. Date and time of the trip is generated based on the current timestamp (and advancing by roughly 1 second per record)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "invalid-detector",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose random city of file containing German cities with postcode\n",
    "if not os.path.exists(\"./pgeocodeDE.txt\"):\n",
    "    # download segment to local file\n",
    "    response = requests.get(\"https://symerio.github.io/postal-codes-data/data/geonames/DE.txt\")\n",
    "    with open(\"./pgeocodeDE.txt\", 'w',encoding='utf8') as out_file:\n",
    "        out_file.write(response.text)\n",
    "    del response\n",
    "\n",
    "geocode_file = open('./pgeocodeDE.txt')\n",
    "geocode_list = list(csv.reader(geocode_file, delimiter='\\t'))[1:] # skip first line (header)\n",
    "random.shuffle(geocode_list)\n",
    "geocode_list = geocode_list[:1000] # take only random 1000 places to generate more overlapping data\n",
    "geocode_file.close()\n",
    "\n",
    "def choose_random_city():\n",
    "    return random.choice(geocode_list)\n",
    "\n",
    "# generate only 1000 driver/rider names to generate more overlapping data\n",
    "names_list = []\n",
    "for i in range(1000):\n",
    "    names_list.append(names.get_full_name())\n",
    "\n",
    "def choose_random_name():\n",
    "    return random.choice(names_list)\n",
    "    \n",
    "# Generation of License Plate\n",
    "# create a pool of letters to choose from\n",
    "letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "numbers = '0123456789'\n",
    "\n",
    "def generate_license_plate():\n",
    "    # generate 3 randomly chosen letters, L1, L2, L3\n",
    "    L1 = random.choice(letters)\n",
    "    L2 = random.choice(letters)\n",
    "    L3 = random.choice(letters)\n",
    "    L4 = random.choice(letters)\n",
    "    # generate 4 randomly chosen numbers, N1, N2, N3, N4\n",
    "    N1 = random.choice(numbers)\n",
    "    N2 = random.choice(numbers)\n",
    "  \n",
    "    # combine it together into one print function\n",
    "    return(L1+L2+'-'+L3+L4+'-'+N1+N2)\n",
    "\n",
    "# Calculation of price based on distance between start city and end destination\n",
    "def calculate_price(v_distance):\n",
    "    v_multiplicator=round(random.uniform(0.8, 2.0),2)\n",
    "    v_price=round(v_distance*v_multiplicator,2)\n",
    "    return(v_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-racing",
   "metadata": {},
   "source": [
    "Let's generate our sample dataset, containing about 300.000 records in total, in order to demonstrate the different Pinot concepts and mechanisms later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "norwegian-composite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records generated\n",
      "5000 records generated\n",
      "10000 records generated\n",
      "15000 records generated\n",
      "20000 records generated\n",
      "25000 records generated\n",
      "30000 records generated\n",
      "35000 records generated\n",
      "40000 records generated\n",
      "45000 records generated\n",
      "50000 records generated\n",
      "55000 records generated\n",
      "60000 records generated\n",
      "65000 records generated\n",
      "70000 records generated\n",
      "75000 records generated\n",
      "80000 records generated\n",
      "85000 records generated\n",
      "90000 records generated\n",
      "95000 records generated\n",
      "100000 records generated\n",
      "105000 records generated\n",
      "110000 records generated\n",
      "115000 records generated\n",
      "120000 records generated\n",
      "125000 records generated\n",
      "130000 records generated\n",
      "135000 records generated\n",
      "140000 records generated\n",
      "145000 records generated\n",
      "150000 records generated\n",
      "155000 records generated\n",
      "160000 records generated\n",
      "165000 records generated\n",
      "170000 records generated\n",
      "175000 records generated\n",
      "180000 records generated\n",
      "185000 records generated\n",
      "190000 records generated\n",
      "195000 records generated\n",
      "200000 records generated\n",
      "205000 records generated\n",
      "210000 records generated\n",
      "215000 records generated\n",
      "220000 records generated\n",
      "225000 records generated\n",
      "230000 records generated\n",
      "235000 records generated\n",
      "240000 records generated\n",
      "245000 records generated\n",
      "250000 records generated\n",
      "255000 records generated\n",
      "260000 records generated\n",
      "265000 records generated\n",
      "270000 records generated\n",
      "275000 records generated\n",
      "280000 records generated\n",
      "285000 records generated\n",
      "290000 records generated\n",
      "295000 records generated\n",
      "300000 records generated\n",
      "305000 records generated\n",
      "done generating 309911 records, ready to do some fancy analytics!\n"
     ]
    }
   ],
   "source": [
    "# begin generating trips data at current time\n",
    "start_timestamp_ms = time.time_ns() // 1000000\n",
    "\n",
    "# Generate data\n",
    "num_records = 300000 + random.randint(5000,10000)\n",
    "for i in range(num_records):\n",
    "    v_start_location = choose_random_city()\n",
    "    v_end_location = choose_random_city()\n",
    "    v_distance = random.randint(5,1000)\n",
    "\n",
    "    # add random jitter, in large system our event stream is probably also not strictly sorted\n",
    "    v_requesttime = start_timestamp_ms + i*1000 + random.randint(0,100);\n",
    "\n",
    "    v_waiting_time_millis = random.randint(1,3600000)\n",
    "    v_trip_time = round((v_distance/random.randint(45,60)) * 60 *60*1000)\n",
    "\n",
    "    record = {\n",
    "        \"rider_name\": choose_random_name(),\n",
    "        \"driver_name\": choose_random_name(),\n",
    "        \"license_plate\": generate_license_plate(),\n",
    "        \"start_location\": v_start_location[2],\n",
    "        \"start_zip_code\": v_start_location[1],\n",
    "        \"start_location_state\": v_start_location[3],\n",
    "        \"end_location\": v_end_location[2],\n",
    "        \"end_zip_code\": v_end_location[1],\n",
    "        \"end_location_state\": v_end_location[3],\n",
    "        \"rider_is_premium\": random.randint(0, 1),\n",
    "        \"count\": 1,\n",
    "        \"payment_amount\": calculate_price(v_distance),\n",
    "        \"payment_tip_amount\": random.randint(5,50),\n",
    "        \"trip_wait_time_millis\": v_waiting_time_millis,\n",
    "        \"rider_rating\": random.randint(0,5),\n",
    "        \"driver_rating\": random.randint(0,5),\n",
    "        \"trip_start_time_millis\": v_requesttime + v_waiting_time_millis,\n",
    "        \"request_time_millis\": v_requesttime,\n",
    "        \"trip_end_time_millis\": v_requesttime + v_waiting_time_millis + v_trip_time\n",
    "    }\n",
    " \n",
    "    producer.send('trips', value=record)\n",
    "        \n",
    "    if i % 5000 == 0:\n",
    "        print(f'{i} records generated')\n",
    "\n",
    "print(f'done generating {num_records} records, ready to do some fancy analytics!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-shift",
   "metadata": {},
   "source": [
    "### Tables\n",
    "\n",
    "Tables represent a collection of related data in Pinot. A table either have the type `OFFLINE` (ingesting pre-built pinot-segments from external stores) or `REALTIME` (data ingestion from streams). The user is not required to know the type of a table when querying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "weekly-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "def query_sql(query):\n",
    "    print(\"query: \" + query)\n",
    "    return requests.get('http://pinot-broker.pinot:8099/query/sql', params={\n",
    "        \"sql\" : query,\n",
    "        \"trace\": \"true\"\n",
    "    }).json()\n",
    "\n",
    "def query_result_to_dataframe(result):\n",
    "    return pd.DataFrame(columns=result['resultTable']['dataSchema']['columnNames'], data=result['resultTable']['rows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-antique",
   "metadata": {},
   "source": [
    "To configure a table, properties like name, type and indexing are required. In the following example, we create an example table which is consuming data from the Kafka topic filled above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "brilliant-needle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{'status': 'Table trips_REALTIME succesfully added'}\n"
     ]
    }
   ],
   "source": [
    "table_config = {\n",
    "  \"tableName\": \"trips\",\n",
    "  \"tableType\": \"REALTIME\",\n",
    "  \"segmentsConfig\": {\n",
    "    \"timeColumnName\": \"trip_start_time_millis\",\n",
    "    \"timeType\": \"MILLISECONDS\",\n",
    "    \"retentionTimeUnit\": \"DAYS\",\n",
    "    \"retentionTimeValue\": \"60\",\n",
    "    \"schemaName\": \"trips\",\n",
    "    \"replication\": \"1\",\n",
    "    \"replicasPerPartition\": \"1\"\n",
    "  },\n",
    "  \"tenants\": {},\n",
    "  \"tableIndexConfig\": {\n",
    "    \"loadMode\": \"MMAP\",\n",
    "    \"streamConfigs\": {\n",
    "      \"streamType\": \"kafka\",\n",
    "      \"stream.kafka.consumer.type\": \"simple\",\n",
    "      \"stream.kafka.topic.name\": \"trips\",\n",
    "      \"stream.kafka.decoder.class.name\": \"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\",\n",
    "      \"stream.kafka.consumer.factory.class.name\": \"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\",\n",
    "      \"stream.kafka.zk.broker.url\": \"pinot-kafka-zookeeper:2181\",\n",
    "      \"stream.kafka.broker.list\": \"pinot-kafka:9092\",\n",
    "      \"realtime.segment.flush.threshold.time\": \"12h\",\n",
    "      \"realtime.segment.flush.threshold.size\": \"20000\",\n",
    "      \"stream.kafka.consumer.prop.auto.offset.reset\": \"smallest\"\n",
    "    },\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"customConfigs\": {}\n",
    "  }\n",
    "} \n",
    "\n",
    "response = requests.post('http://pinot-controller.pinot:9000/tables', json=table_config)\n",
    "print(response)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-senior",
   "metadata": {},
   "source": [
    "After creation, data records of the Kafka Topic are loaded into the table. To execute a query, the SQL statement is sent to the broker of the Pinot cluster. The response contains the result records, as well as query statistics of the execution.\n",
    "\n",
    "While our data is loading, let's query the example table to find out the top 5 states where trips of our ride sharing platform start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compound-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "    SELECT start_location_state, SUM(count) as trips_count\n",
      "    FROM trips\n",
      "    GROUP BY start_location_state\n",
      "    ORDER BY trips_count DESC\n",
      "    LIMIT 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_location_state</th>\n",
       "      <th>trips_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayern</td>\n",
       "      <td>1534.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rheinland-Pfalz</td>\n",
       "      <td>1448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Niedersachsen</td>\n",
       "      <td>1423.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>924.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sachsen-Anhalt</td>\n",
       "      <td>864.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_location_state  trips_count\n",
       "0               Bayern       1534.0\n",
       "1      Rheinland-Pfalz       1448.0\n",
       "2        Niedersachsen       1423.0\n",
       "3          Brandenburg        924.0\n",
       "4       Sachsen-Anhalt        864.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result_to_dataframe(query_sql(\"\"\"\n",
    "    SELECT start_location_state, SUM(count) as trips_count\n",
    "    FROM trips\n",
    "    GROUP BY start_location_state\n",
    "    ORDER BY trips_count DESC\n",
    "    LIMIT 5\"\"\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-taiwan",
   "metadata": {},
   "source": [
    "# Segmentation in Pinot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-repeat",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Table contents in Pinot are expected to grow infinitely and thus need to be distributed across multiple nodes. Therefore, the tables' dataset is split into segments, which are comparable to shards/partitions in classical RDBMSs. In Pinot, segmentation is done in a time-based fashion, meaning that configured timestamps of records in a given segment will be close to each other.\n",
    "Segments store all columns of a table and organize data in columnar orientation for high encoding efficiency and optional pre-aggregation of metrics. In addition to the data itself, segments contain indices and other lookup-related data structures like dictionaries.\n",
    "\n",
    "As Pinot is not a general-purpose database (data is immutable), it cannot be used as an application's \"main datastore\". Like other OLAP stores, Pinot is supposed to run next to the application's \"main datastore\" and its data has to be imported separately (ingestion). In order to facilitate near-realtime analytical queries, for example like the ones powering LinkedIn's well-known \"Who viewed my profile\" functionality, data is typically ingested into Pinot via event streaming platforms, like Apache Kafka (stream ingestion). In contrast to classical RDBMSs, Pinot comes with built-in support for directly reading from Kafka event streams.\n",
    "However, data can also be ingested from traditional batch processing workflows, for example realized with Apache Hadoop or Apache Spark (batch ingestion).\n",
    "\n",
    "Pinot tables are either defined as realtime or offline tables. Tables of both types are broken into segments. For realtime tables, data is consumed directly from event streams by Pinot servers as-is without any additional processing. Segments are built inside Pinot and are completed once a given threshold in size or time is reached. Segments for offline tables are built outside of Pinot in batch processing jobs, that might perform additional data deduplication or similar processing, and uploaded to the Pinot controller. Both table types might be combined to form hybrid tables, that allow both realtime analytics as well as long-term data storage (covered later on)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seventh-citizenship",
   "metadata": {},
   "source": [
    "## Realtime Data Ingestion\n",
    "\n",
    "To demonstrate how segments work in Pinot, we're going to focus on realtime data ingestion first. In the following examples, we'll be using the controller's and broker's REST APIs in order to dynamically create realtime tables, retrieve segment metadata and execute SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "particular-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpers for the upcoming examples\n",
    "def server_name_from_instance(instance):\n",
    "    return re.search('pinot-server-[0-9]+', instance).group()\n",
    "\n",
    "def extract_query_statistics_from_result(result):\n",
    "    query_statistics_fields = [\"numServersQueried\",\"numServersResponded\",\"numSegmentsQueried\",\"numSegmentsProcessed\",\"numSegmentsMatched\",\"numConsumingSegmentsQueried\",\"numDocsScanned\",\"numEntriesScannedInFilter\",\"numEntriesScannedPostFilter\",\"numGroupsLimitReached\",\"totalDocs\",\"timeUsedMs\"]\n",
    "    return { key: result[key] for key in query_statistics_fields }\n",
    "\n",
    "def extract_query_statistics_from_result_dataframe(result):\n",
    "    return pd.DataFrame({\"value\": extract_query_statistics_from_result(result)})\n",
    "\n",
    "ordinal_pattern = re.compile(r'__[0-9]+__([0-9]+)__')\n",
    "def sort_by_ascending_ordinal(segments):\n",
    "    segments.sort(key=lambda L: (int(ordinal_pattern.search(L).group(1)), L))\n",
    "\n",
    "def segment_metadata_for_table(table):\n",
    "    segments = requests.get(f'http://pinot-controller.pinot:9000/segments/{table}').json()\n",
    "    \n",
    "    segment_metadata = {}\n",
    "    for segments_item in segments:\n",
    "        for table_type, type_segments in segments_item.items():\n",
    "            for segment in type_segments:\n",
    "                segment_type_name = f\"{segment}_{table_type}\"\n",
    "                segment_metadata[segment_type_name] = requests.get(f'http://pinot-controller.pinot:9000/segments/{table}/{segment}/metadata').json()\n",
    "    \n",
    "    return segment_metadata\n",
    "\n",
    "def segment_metadata_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\"):\n",
    "    segments_of_type = []\n",
    "    for segment in segment_metadata.keys():\n",
    "        if segment.endswith(\"_\" + table_type):\n",
    "            segments_of_type.append(segment)\n",
    "    \n",
    "    sort_by_ascending_ordinal(segments_of_type)\n",
    "    return segment_metadata[segments_of_type[n]]\n",
    "\n",
    "\n",
    "def start_time_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\"):\n",
    "    return segment_metadata_of_nth_segment(segment_metadata, n, table_type)[\"segment.start.time\"]\n",
    "\n",
    "def wait_for_table_to_finish_loading(table, wait_time=15):\n",
    "    last_total_docs = -1\n",
    "    while True:\n",
    "        response = requests.post('http://pinot-broker.pinot:8099/query/sql', json={\"sql\" : f\"SELECT * FROM {table} LIMIT 1\"}).json()\n",
    "        total_docs = response[\"totalDocs\"]\n",
    "        if total_docs == last_total_docs:\n",
    "            print(f\"--Consumption of generated data for table {table} finished, (loaded {last_total_docs} docs)--\")\n",
    "            break\n",
    "        \n",
    "        last_total_docs = total_docs\n",
    "        print(f\"waiting for table {table} to finish loading (loaded {last_total_docs} docs)\")\n",
    "        time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-punishment",
   "metadata": {},
   "source": [
    "At first, we will create two realtime tables. Both will be using the `trips` schema created above and read from the `trips` topic in Kafka, that was also created and filled with random records above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aware-cabinet",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# common configuration used for both tables\n",
    "table_config_template = {\n",
    "  \"tableName\": \"\",\n",
    "  \"tableType\": \"REALTIME\",\n",
    "  \"segmentsConfig\": {\n",
    "    \"timeColumnName\": \"trip_start_time_millis\",\n",
    "    \"timeType\": \"MILLISECONDS\",\n",
    "    \"retentionTimeUnit\": \"DAYS\",\n",
    "    \"retentionTimeValue\": \"60\",\n",
    "    \"schemaName\": \"trips\",\n",
    "  },\n",
    "  \"tenants\": {},\n",
    "  \"tableIndexConfig\": {\n",
    "    \"loadMode\": \"MMAP\",\n",
    "    \"invertedIndexColumns\": [\n",
    "        \"rider_name\",\n",
    "        \"driver_name\",\n",
    "        \"start_location\",\n",
    "        \"end_location\"\n",
    "    ],\n",
    "    \"streamConfigs\": {\n",
    "      \"streamType\": \"kafka\",\n",
    "      \"stream.kafka.topic.name\": \"trips\",\n",
    "      \"stream.kafka.consumer.type\": \"simple\",\n",
    "      \"stream.kafka.decoder.class.name\": \"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\",\n",
    "      \"stream.kafka.consumer.factory.class.name\": \"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\",\n",
    "      \"stream.kafka.zk.broker.url\": \"pinot-kafka-zookeeper:2181\",\n",
    "      \"stream.kafka.broker.list\": \"pinot-kafka:9092\",\n",
    "      \"stream.kafka.consumer.prop.auto.offset.reset\": \"smallest\"\n",
    "    }\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"customConfigs\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-package",
   "metadata": {},
   "source": [
    "Pinot servers will continuously read from the Kafka topic into memory and compile a segment until a configured threshold is reached. The first table is configured to flush the new in-memory segment to disk, once either 12 hours have passed or the segment contains 80,000 rows (which will be the case for our example, as the data is already waiting in the Kafka stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specified-stopping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Table trips_segmentation_1_REALTIME succesfully added'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create first table\n",
    "table_config = copy.deepcopy(table_config_template)\n",
    "table_config[\"tableName\"] = \"trips_segmentation_1\"\n",
    "table_config[\"segmentsConfig\"][\"replication\"] = \"1\"\n",
    "table_config[\"segmentsConfig\"][\"replicasPerPartition\"] = \"1\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.time\"] = \"12h\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.size\"] = \"80000\"\n",
    "display(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-tennessee",
   "metadata": {},
   "source": [
    "In contrast to the first table, the second one will target a segment size of 50,000 rows and will additionally create 3 replicas of each segment on different server instances for data availability (fault tolerance) and load distribution of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "derived-presentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'Table trips_segmentation_2_REALTIME succesfully added'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create second table\n",
    "table_config = copy.deepcopy(table_config_template)\n",
    "table_config[\"tableName\"] = \"trips_segmentation_2\"\n",
    "table_config[\"segmentsConfig\"][\"replication\"] = \"3\"\n",
    "table_config[\"segmentsConfig\"][\"replicasPerPartition\"] = \"3\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.time\"] = \"12h\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.size\"] = \"50000\"\n",
    "display(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-still",
   "metadata": {},
   "source": [
    "Let's wait for the tables to finish loading the data from Kafka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "explicit-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for table trips_segmentation_1 to finish loading (loaded 54899 docs)\n",
      "waiting for table trips_segmentation_1 to finish loading (loaded 93568 docs)\n",
      "waiting for table trips_segmentation_1 to finish loading (loaded 160000 docs)\n",
      "waiting for table trips_segmentation_1 to finish loading (loaded 240000 docs)\n",
      "waiting for table trips_segmentation_1 to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_segmentation_1 finished, (loaded 309911 docs)--\n",
      "waiting for table trips_segmentation_2 to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_segmentation_2 finished, (loaded 309911 docs)--\n"
     ]
    }
   ],
   "source": [
    "wait_for_table_to_finish_loading(\"trips_segmentation_1\")\n",
    "wait_for_table_to_finish_loading(\"trips_segmentation_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-scientist",
   "metadata": {},
   "source": [
    "The controller stores metadata for each segment, which can be viewed via its REST API. Each segment's metadata contains general information such as the table type, table name and time unit as well as segment-specific information such as the number of records (`segment.total.docs`), the timestamp of the segment's first and last record (`segment.start.time`, `segment.end.time`) and the segment's status (`segment.realtime.status`).\n",
    "New realtime segments start in status `IN_PROGRESS`, which means that the segment is currently consuming data from the Kafka topic. Once the size or time threshold is reached, the consuming servers start a segment commit protocol in order to agree on the last record that shall be included in the segment. Once the commit protocol is completed, the segment transitions to `DONE` and the servers flush the data to disk. Afterwards, a new segment is started again to consume further data from the event stream.\n",
    "\n",
    "We can now query the controller's REST API to retrieve metadata for all segments in both our tables.\n",
    "The first table contains less segments, but each segment contains a higher number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "destroyed-character",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trips_segmentation_1__0__0__20210411T1645Z_REALTIME</th>\n",
       "      <th>trips_segmentation_1__0__1__20210411T1646Z_REALTIME</th>\n",
       "      <th>trips_segmentation_1__0__2__20210411T1646Z_REALTIME</th>\n",
       "      <th>trips_segmentation_1__0__3__20210411T1646Z_REALTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>segment.realtime.endOffset</th>\n",
       "      <td>80000</td>\n",
       "      <td>160000</td>\n",
       "      <td>240000</td>\n",
       "      <td>9223372036854775807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.time.unit</th>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.start.time</th>\n",
       "      <td>1618159486495</td>\n",
       "      <td>1618239458972</td>\n",
       "      <td>1618319463311</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.flush.threshold.size</th>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.realtime.startOffset</th>\n",
       "      <td>0</td>\n",
       "      <td>80000</td>\n",
       "      <td>160000</td>\n",
       "      <td>240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.end.time</th>\n",
       "      <td>1618242914999</td>\n",
       "      <td>1618322911292</td>\n",
       "      <td>1618402828195</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.total.docs</th>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>80000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.table.name</th>\n",
       "      <td>trips_segmentation_1_REALTIME</td>\n",
       "      <td>trips_segmentation_1_REALTIME</td>\n",
       "      <td>trips_segmentation_1_REALTIME</td>\n",
       "      <td>trips_segmentation_1_REALTIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.realtime.numReplicas</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.creation.time</th>\n",
       "      <td>1618159544768</td>\n",
       "      <td>1618159567495</td>\n",
       "      <td>1618159588274</td>\n",
       "      <td>1618159603181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.realtime.download.url</th>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.name</th>\n",
       "      <td>trips_segmentation_1__0__0__20210411T1645Z</td>\n",
       "      <td>trips_segmentation_1__0__1__20210411T1646Z</td>\n",
       "      <td>trips_segmentation_1__0__2__20210411T1646Z</td>\n",
       "      <td>trips_segmentation_1__0__3__20210411T1646Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.index.version</th>\n",
       "      <td>v3</td>\n",
       "      <td>v3</td>\n",
       "      <td>v3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom.map</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.flush.threshold.time</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.type</th>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.crc</th>\n",
       "      <td>3345569707</td>\n",
       "      <td>4004358683</td>\n",
       "      <td>2108247896</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.realtime.status</th>\n",
       "      <td>DONE</td>\n",
       "      <td>DONE</td>\n",
       "      <td>DONE</td>\n",
       "      <td>IN_PROGRESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trips_segmentation_1__0__0__20210411T1645Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                 80000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618159486495    \n",
       "segment.flush.threshold.size                                               80000    \n",
       "segment.realtime.startOffset                                                   0    \n",
       "segment.end.time                                                   1618242914999    \n",
       "segment.total.docs                                                         80000    \n",
       "segment.table.name                                 trips_segmentation_1_REALTIME    \n",
       "segment.realtime.numReplicas                                                   1    \n",
       "segment.creation.time                                              1618159544768    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_1__0__0__20210411T1645Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                           3345569707    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_1__0__1__20210411T1646Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                160000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618239458972    \n",
       "segment.flush.threshold.size                                               80000    \n",
       "segment.realtime.startOffset                                               80000    \n",
       "segment.end.time                                                   1618322911292    \n",
       "segment.total.docs                                                         80000    \n",
       "segment.table.name                                 trips_segmentation_1_REALTIME    \n",
       "segment.realtime.numReplicas                                                   1    \n",
       "segment.creation.time                                              1618159567495    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_1__0__1__20210411T1646Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                           4004358683    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_1__0__2__20210411T1646Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                240000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618319463311    \n",
       "segment.flush.threshold.size                                               80000    \n",
       "segment.realtime.startOffset                                              160000    \n",
       "segment.end.time                                                   1618402828195    \n",
       "segment.total.docs                                                         80000    \n",
       "segment.table.name                                 trips_segmentation_1_REALTIME    \n",
       "segment.realtime.numReplicas                                                   1    \n",
       "segment.creation.time                                              1618159588274    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_1__0__2__20210411T1646Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                           2108247896    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_1__0__3__20210411T1646Z_REALTIME  \n",
       "segment.realtime.endOffset                                   9223372036854775807   \n",
       "segment.time.unit                                                           None   \n",
       "segment.start.time                                                            -1   \n",
       "segment.flush.threshold.size                                               80000   \n",
       "segment.realtime.startOffset                                              240000   \n",
       "segment.end.time                                                              -1   \n",
       "segment.total.docs                                                            -1   \n",
       "segment.table.name                                 trips_segmentation_1_REALTIME   \n",
       "segment.realtime.numReplicas                                                   1   \n",
       "segment.creation.time                                              1618159603181   \n",
       "segment.realtime.download.url                                               None   \n",
       "segment.name                          trips_segmentation_1__0__3__20210411T1646Z   \n",
       "segment.index.version                                                       None   \n",
       "custom.map                                                                  None   \n",
       "segment.flush.threshold.time                                                None   \n",
       "segment.type                                                            REALTIME   \n",
       "segment.crc                                                                   -1   \n",
       "segment.realtime.status                                              IN_PROGRESS   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_metadata_1 = segment_metadata_for_table(\"trips_segmentation_1\")\n",
    "pd.DataFrame(segment_metadata_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-physiology",
   "metadata": {},
   "source": [
    "The segment metadata for the second table shows more segments. Each of them has a lower number of total records and 3 replicas (`segment.realtime.numReplicas`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "facial-being",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trips_segmentation_2__0__0__20210411T1645Z_REALTIME</th>\n",
       "      <th>trips_segmentation_2__0__1__20210411T1646Z_REALTIME</th>\n",
       "      <th>trips_segmentation_2__0__2__20210411T1646Z_REALTIME</th>\n",
       "      <th>trips_segmentation_2__0__3__20210411T1646Z_REALTIME</th>\n",
       "      <th>trips_segmentation_2__0__4__20210411T1646Z_REALTIME</th>\n",
       "      <th>trips_segmentation_2__0__5__20210411T1646Z_REALTIME</th>\n",
       "      <th>trips_segmentation_2__0__6__20210411T1646Z_REALTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>segment.realtime.endOffset</th>\n",
       "      <td>50000</td>\n",
       "      <td>100000</td>\n",
       "      <td>150000</td>\n",
       "      <td>200000</td>\n",
       "      <td>250000</td>\n",
       "      <td>300000</td>\n",
       "      <td>9223372036854775807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.time.unit</th>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>MILLISECONDS</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.start.time</th>\n",
       "      <td>1618159486495</td>\n",
       "      <td>1618209432220</td>\n",
       "      <td>1618259456044</td>\n",
       "      <td>1618309433532</td>\n",
       "      <td>1618359464465</td>\n",
       "      <td>1618409462241</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.flush.threshold.size</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.realtime.startOffset</th>\n",
       "      <td>0</td>\n",
       "      <td>50000</td>\n",
       "      <td>100000</td>\n",
       "      <td>150000</td>\n",
       "      <td>200000</td>\n",
       "      <td>250000</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.end.time</th>\n",
       "      <td>1618212853532</td>\n",
       "      <td>1618262875514</td>\n",
       "      <td>1618312939951</td>\n",
       "      <td>1618362932066</td>\n",
       "      <td>1618412895838</td>\n",
       "      <td>1618462970400</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.total.docs</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.table.name</th>\n",
       "      <td>trips_segmentation_2_REALTIME</td>\n",
       "      <td>trips_segmentation_2_REALTIME</td>\n",
       "      <td>trips_segmentation_2_REALTIME</td>\n",
       "      <td>trips_segmentation_2_REALTIME</td>\n",
       "      <td>trips_segmentation_2_REALTIME</td>\n",
       "      <td>trips_segmentation_2_REALTIME</td>\n",
       "      <td>trips_segmentation_2_REALTIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.realtime.numReplicas</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.creation.time</th>\n",
       "      <td>1618159546358</td>\n",
       "      <td>1618159564259</td>\n",
       "      <td>1618159579112</td>\n",
       "      <td>1618159591215</td>\n",
       "      <td>1618159601406</td>\n",
       "      <td>1618159611054</td>\n",
       "      <td>1618159619674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.realtime.download.url</th>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>http://pinot-controller-0.pinot-controller-hea...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.name</th>\n",
       "      <td>trips_segmentation_2__0__0__20210411T1645Z</td>\n",
       "      <td>trips_segmentation_2__0__1__20210411T1646Z</td>\n",
       "      <td>trips_segmentation_2__0__2__20210411T1646Z</td>\n",
       "      <td>trips_segmentation_2__0__3__20210411T1646Z</td>\n",
       "      <td>trips_segmentation_2__0__4__20210411T1646Z</td>\n",
       "      <td>trips_segmentation_2__0__5__20210411T1646Z</td>\n",
       "      <td>trips_segmentation_2__0__6__20210411T1646Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.index.version</th>\n",
       "      <td>v3</td>\n",
       "      <td>v3</td>\n",
       "      <td>v3</td>\n",
       "      <td>v3</td>\n",
       "      <td>v3</td>\n",
       "      <td>v3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>custom.map</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.flush.threshold.time</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.type</th>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "      <td>REALTIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.crc</th>\n",
       "      <td>1821723182</td>\n",
       "      <td>754665878</td>\n",
       "      <td>2061197877</td>\n",
       "      <td>3461826500</td>\n",
       "      <td>3358849698</td>\n",
       "      <td>2782318493</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>segment.realtime.status</th>\n",
       "      <td>DONE</td>\n",
       "      <td>DONE</td>\n",
       "      <td>DONE</td>\n",
       "      <td>DONE</td>\n",
       "      <td>DONE</td>\n",
       "      <td>DONE</td>\n",
       "      <td>IN_PROGRESS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trips_segmentation_2__0__0__20210411T1645Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                 50000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618159486495    \n",
       "segment.flush.threshold.size                                               50000    \n",
       "segment.realtime.startOffset                                                   0    \n",
       "segment.end.time                                                   1618212853532    \n",
       "segment.total.docs                                                         50000    \n",
       "segment.table.name                                 trips_segmentation_2_REALTIME    \n",
       "segment.realtime.numReplicas                                                   3    \n",
       "segment.creation.time                                              1618159546358    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_2__0__0__20210411T1645Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                           1821723182    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_2__0__1__20210411T1646Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                100000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618209432220    \n",
       "segment.flush.threshold.size                                               50000    \n",
       "segment.realtime.startOffset                                               50000    \n",
       "segment.end.time                                                   1618262875514    \n",
       "segment.total.docs                                                         50000    \n",
       "segment.table.name                                 trips_segmentation_2_REALTIME    \n",
       "segment.realtime.numReplicas                                                   3    \n",
       "segment.creation.time                                              1618159564259    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_2__0__1__20210411T1646Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                            754665878    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_2__0__2__20210411T1646Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                150000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618259456044    \n",
       "segment.flush.threshold.size                                               50000    \n",
       "segment.realtime.startOffset                                              100000    \n",
       "segment.end.time                                                   1618312939951    \n",
       "segment.total.docs                                                         50000    \n",
       "segment.table.name                                 trips_segmentation_2_REALTIME    \n",
       "segment.realtime.numReplicas                                                   3    \n",
       "segment.creation.time                                              1618159579112    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_2__0__2__20210411T1646Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                           2061197877    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_2__0__3__20210411T1646Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                200000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618309433532    \n",
       "segment.flush.threshold.size                                               50000    \n",
       "segment.realtime.startOffset                                              150000    \n",
       "segment.end.time                                                   1618362932066    \n",
       "segment.total.docs                                                         50000    \n",
       "segment.table.name                                 trips_segmentation_2_REALTIME    \n",
       "segment.realtime.numReplicas                                                   3    \n",
       "segment.creation.time                                              1618159591215    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_2__0__3__20210411T1646Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                           3461826500    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_2__0__4__20210411T1646Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                250000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618359464465    \n",
       "segment.flush.threshold.size                                               50000    \n",
       "segment.realtime.startOffset                                              200000    \n",
       "segment.end.time                                                   1618412895838    \n",
       "segment.total.docs                                                         50000    \n",
       "segment.table.name                                 trips_segmentation_2_REALTIME    \n",
       "segment.realtime.numReplicas                                                   3    \n",
       "segment.creation.time                                              1618159601406    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_2__0__4__20210411T1646Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                           3358849698    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_2__0__5__20210411T1646Z_REALTIME  \\\n",
       "segment.realtime.endOffset                                                300000    \n",
       "segment.time.unit                                                   MILLISECONDS    \n",
       "segment.start.time                                                 1618409462241    \n",
       "segment.flush.threshold.size                                               50000    \n",
       "segment.realtime.startOffset                                              250000    \n",
       "segment.end.time                                                   1618462970400    \n",
       "segment.total.docs                                                         50000    \n",
       "segment.table.name                                 trips_segmentation_2_REALTIME    \n",
       "segment.realtime.numReplicas                                                   3    \n",
       "segment.creation.time                                              1618159611054    \n",
       "segment.realtime.download.url  http://pinot-controller-0.pinot-controller-hea...    \n",
       "segment.name                          trips_segmentation_2__0__5__20210411T1646Z    \n",
       "segment.index.version                                                         v3    \n",
       "custom.map                                                                  None    \n",
       "segment.flush.threshold.time                                                None    \n",
       "segment.type                                                            REALTIME    \n",
       "segment.crc                                                           2782318493    \n",
       "segment.realtime.status                                                     DONE    \n",
       "\n",
       "                              trips_segmentation_2__0__6__20210411T1646Z_REALTIME  \n",
       "segment.realtime.endOffset                                   9223372036854775807   \n",
       "segment.time.unit                                                           None   \n",
       "segment.start.time                                                            -1   \n",
       "segment.flush.threshold.size                                               50000   \n",
       "segment.realtime.startOffset                                              300000   \n",
       "segment.end.time                                                              -1   \n",
       "segment.total.docs                                                            -1   \n",
       "segment.table.name                                 trips_segmentation_2_REALTIME   \n",
       "segment.realtime.numReplicas                                                   3   \n",
       "segment.creation.time                                              1618159619674   \n",
       "segment.realtime.download.url                                               None   \n",
       "segment.name                          trips_segmentation_2__0__6__20210411T1646Z   \n",
       "segment.index.version                                                       None   \n",
       "custom.map                                                                  None   \n",
       "segment.flush.threshold.time                                                None   \n",
       "segment.type                                                            REALTIME   \n",
       "segment.crc                                                                   -1   \n",
       "segment.realtime.status                                              IN_PROGRESS   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_metadata_2 = segment_metadata_for_table(\"trips_segmentation_2\")\n",
    "pd.DataFrame(segment_metadata_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-salmon",
   "metadata": {},
   "source": [
    "Pinot brokers are responsible for executing queries against the database. When a broker receives a new query, it sends multiple subqueries to Pinot servers that are hosting the segments belonging to the queried table. Once it has received results from all queried servers, it merges the subresults and returns the aggregated result to the client.\n",
    "In order to efficiently execute queries, brokers use segment metadata to figure out, which segments need to be queried. For example, if we want to list the top 5 drivers in terms of trips count in a given timeframe, only the segments hosting data of the timeframe need to be queried.\n",
    "\n",
    "To demonstrate this behaviour, we call the broker's REST API and query data from the time range of the first segment (before start time of the second segment). In the returned query statistics we can see, that not all segments of the table (`numSegmentsQueried`) are actually processed, but only 2 of them (`numSegmentsMatched`). This is because the last (the consuming) segment is always queried, as the metadata is not yet completed and so the broker can't tell upfront, if the last segment might contain relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "drawn-depression",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "    SELECT driver_name, sum(count) AS trips_count\n",
      "    FROM trips_segmentation_1\n",
      "    WHERE trip_start_time_millis BETWEEN 1618159486495 AND 1618239458972\n",
      "    GROUP BY driver_name\n",
      "    ORDER BY trips_count desc\n",
      "    LIMIT 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_name</th>\n",
       "      <th>trips_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Reese</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dennis Smith</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kelly Sprague</td>\n",
       "      <td>113.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Darius Blanco</td>\n",
       "      <td>105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Terra Bell</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     driver_name  trips_count\n",
       "0    Alice Reese        161.0\n",
       "1   Dennis Smith        142.0\n",
       "2  Kelly Sprague        113.0\n",
       "3  Darius Blanco        105.0\n",
       "4     Terra Bell        104.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>numConsumingSegmentsQueried</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numDocsScanned</th>\n",
       "      <td>78268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numEntriesScannedInFilter</th>\n",
       "      <td>160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numEntriesScannedPostFilter</th>\n",
       "      <td>156536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numGroupsLimitReached</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numSegmentsMatched</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numSegmentsProcessed</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numSegmentsQueried</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numServersQueried</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numServersResponded</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeUsedMs</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalDocs</th>\n",
       "      <td>309911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              value\n",
       "numConsumingSegmentsQueried       1\n",
       "numDocsScanned                78268\n",
       "numEntriesScannedInFilter    160000\n",
       "numEntriesScannedPostFilter  156536\n",
       "numGroupsLimitReached         False\n",
       "numSegmentsMatched                2\n",
       "numSegmentsProcessed              2\n",
       "numSegmentsQueried                4\n",
       "numServersQueried                 1\n",
       "numServersResponded               1\n",
       "timeUsedMs                       27\n",
       "totalDocs                    309911"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get data from first segment (consuming segment is always queried because of uncompleted metadata)\n",
    "query_for_trips_segmentation_1 = f\"\"\"\n",
    "    SELECT driver_name, sum(count) AS trips_count\n",
    "    FROM trips_segmentation_1\n",
    "    WHERE trip_start_time_millis BETWEEN {start_time_of_nth_segment(segment_metadata_1, 0)} AND {int(start_time_of_nth_segment(segment_metadata_1, 1))-1}\n",
    "    GROUP BY driver_name\n",
    "    ORDER BY trips_count desc\n",
    "    LIMIT 5\"\"\"\n",
    "\n",
    "query_result = query_sql(query_for_trips_segmentation_1)\n",
    "display(query_result_to_dataframe(query_result))\n",
    "display(extract_query_statistics_from_result_dataframe(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-number",
   "metadata": {},
   "source": [
    "The second query targets the second table and lists the top 5 drivers according to rating over the time range of the first 3 segments.\n",
    "Similarly to the query above, only relevant segments need to be processed for this query.\n",
    "However, in contrast to the first query execution, the broker can make use of the segment replication and can distribute the subqueries for individual segments across different servers (note that `numServersQueried` is now 3 instead of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "distant-violation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "    SELECT driver_name, avg(driver_rating) AS rating\n",
      "    FROM trips_segmentation_2\n",
      "    WHERE trip_start_time_millis BETWEEN 1618159486495 AND 1618309433532\n",
      "    GROUP BY driver_name\n",
      "    ORDER BY rating desc\n",
      "    LIMIT 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jeannine Robison</td>\n",
       "      <td>2.947761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jason Phillips</td>\n",
       "      <td>2.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mindy Smith</td>\n",
       "      <td>2.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfred Obrien</td>\n",
       "      <td>2.920635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jaime Adams</td>\n",
       "      <td>2.890411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        driver_name    rating\n",
       "0  Jeannine Robison  2.947761\n",
       "1    Jason Phillips  2.945946\n",
       "2       Mindy Smith  2.926667\n",
       "3     Alfred Obrien  2.920635\n",
       "4       Jaime Adams  2.890411"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>numConsumingSegmentsQueried</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numDocsScanned</th>\n",
       "      <td>148256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numEntriesScannedInFilter</th>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numEntriesScannedPostFilter</th>\n",
       "      <td>296512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numGroupsLimitReached</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numSegmentsMatched</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numSegmentsProcessed</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numSegmentsQueried</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numServersQueried</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numServersResponded</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeUsedMs</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totalDocs</th>\n",
       "      <td>309911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              value\n",
       "numConsumingSegmentsQueried       1\n",
       "numDocsScanned               148256\n",
       "numEntriesScannedInFilter    100000\n",
       "numEntriesScannedPostFilter  296512\n",
       "numGroupsLimitReached         False\n",
       "numSegmentsMatched                4\n",
       "numSegmentsProcessed              4\n",
       "numSegmentsQueried                7\n",
       "numServersQueried                 3\n",
       "numServersResponded               3\n",
       "timeUsedMs                      127\n",
       "totalDocs                    309911"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get data from first 3 segments (consuming segment is always queried because of uncompleted metadata)\n",
    "query_for_trips_segmentation_2 = f\"\"\"\n",
    "    SELECT driver_name, avg(driver_rating) AS rating\n",
    "    FROM trips_segmentation_2\n",
    "    WHERE trip_start_time_millis BETWEEN {start_time_of_nth_segment(segment_metadata_2, 0)} AND {int(start_time_of_nth_segment(segment_metadata_2, 3))-1}\n",
    "    GROUP BY driver_name\n",
    "    ORDER BY rating desc\n",
    "    LIMIT 5\"\"\"\n",
    "\n",
    "query_result = query_sql(query_for_trips_segmentation_2)\n",
    "display(query_result_to_dataframe(query_result))\n",
    "display(extract_query_statistics_from_result_dataframe(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-native",
   "metadata": {},
   "source": [
    "## Query Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solid-yield",
   "metadata": {},
   "source": [
    "In order to efficiently distribute queries across the fleet of servers, brokers maintain so called routing tables, which contain mappings between segments of a table and servers where they are hosted on. \n",
    "In case of replicated segments (like in the second table), the routing table contains entries for all servers hosting a single segment. When queries arrive at the broker, the routing tables and segment metadata allow to efficiently scatter queries across servers to balance load across the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dietary-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpers for the upcoming examples\n",
    "def routing_table_for_query(query):\n",
    "    print(\"query: \" + query)\n",
    "    return requests.get('http://pinot-broker.pinot:8099/debug/routingTable/sql', params={\n",
    "        \"query\" : query\n",
    "    }).json()\n",
    "\n",
    "def routing_table_for_table(table):\n",
    "    return requests.get(f'http://pinot-broker.pinot:8099/debug/routingTable/{table}').json()\n",
    "\n",
    "def external_view_for_table(table):\n",
    "    return requests.get(f'http://pinot-controller.pinot:9000/tables/{table}/externalview').json()\n",
    "\n",
    "def routing_table_for_query_dataframe(query):\n",
    "    rt = routing_table_for_query(query)\n",
    "    rt_data = {}\n",
    "\n",
    "    for server, server_segments in rt.items():\n",
    "        server_name = server_name_from_instance(server)\n",
    "        for s in server_segments:\n",
    "            rt_data[s] = server_name\n",
    "\n",
    "    rt_data_list = []\n",
    "    for segment, server in rt_data.items():\n",
    "        rt_data_list.append({\"segment\": segment, \"server\": server})\n",
    "\n",
    "    rt_data_list.sort(key=lambda L: (int(ordinal_pattern.search(L[\"segment\"]).group(1)), L))\n",
    "    return pd.DataFrame(rt_data_list)\n",
    "\n",
    "def routing_table_for_table_dataframe(table):\n",
    "    rt = routing_table_for_table(table)\n",
    "    rt_data = {}\n",
    "\n",
    "    for table_name_type, table_rt in rt.items():\n",
    "        table_type = re.search('REALTIME|OFFLINE', table_name_type).group()\n",
    "        for server, server_segments in table_rt.items():\n",
    "            server_name = server_name_from_instance(server)\n",
    "            for s in server_segments:\n",
    "                try:\n",
    "                    rt_data[s][table_type] = server_name\n",
    "                except KeyError:\n",
    "                    rt_data[s] = {table_type: server_name}\n",
    "\n",
    "    rt_data_list = []\n",
    "    for segment, type_server in rt_data.items():\n",
    "        segment_data = {\"segment\": segment}\n",
    "        for table_type, server in type_server.items():\n",
    "            segment_data[table_type] = server\n",
    "        rt_data_list.append(segment_data)\n",
    "\n",
    "    rt_data_list.sort(key=lambda L: (int(ordinal_pattern.search(L[\"segment\"]).group(1)), L))\n",
    "    return pd.DataFrame(rt_data_list)\n",
    "\n",
    "def external_view_for_table_dataframe(table):\n",
    "    ev = external_view_for_table(table)\n",
    "    ev_data = {}\n",
    "\n",
    "    for table_type, ev_per_type in ev.items():\n",
    "        if ev_per_type == None:\n",
    "            continue\n",
    "        \n",
    "        for segment, segment_servers in ev_per_type.items():\n",
    "            if not segment in ev_data:\n",
    "                ev_data[segment] = {}\n",
    "            for server, state in segment_servers.items():\n",
    "                server_name = server_name_from_instance(server)\n",
    "                try:\n",
    "                    ev_data[segment][table_type].append(server_name)\n",
    "                except KeyError:\n",
    "                    ev_data[segment][table_type] = [server_name]\n",
    "\n",
    "    return pd.DataFrame(ev_data).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-vietnam",
   "metadata": {},
   "source": [
    "First, let's take a look at the external view for both tables. The external view shows an overview, which segments are available on which server. In case of the first table, each segment is only available on a single server. The second table has a replica of each segment on every server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mysterious-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REALTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_1__0__0__20210411T1645Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_1__0__1__20210411T1646Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_1__0__2__20210411T1646Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_1__0__3__20210411T1646Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    REALTIME\n",
       "trips_segmentation_1__0__0__20210411T1645Z  [pinot-server-1]\n",
       "trips_segmentation_1__0__1__20210411T1646Z  [pinot-server-1]\n",
       "trips_segmentation_1__0__2__20210411T1646Z  [pinot-server-1]\n",
       "trips_segmentation_1__0__3__20210411T1646Z  [pinot-server-1]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REALTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_2__0__0__20210411T1645Z</th>\n",
       "      <td>[pinot-server-0, pinot-server-1, pinot-server-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_2__0__1__20210411T1646Z</th>\n",
       "      <td>[pinot-server-0, pinot-server-1, pinot-server-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_2__0__2__20210411T1646Z</th>\n",
       "      <td>[pinot-server-0, pinot-server-1, pinot-server-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_2__0__3__20210411T1646Z</th>\n",
       "      <td>[pinot-server-0, pinot-server-1, pinot-server-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_2__0__4__20210411T1646Z</th>\n",
       "      <td>[pinot-server-0, pinot-server-1, pinot-server-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_2__0__5__20210411T1646Z</th>\n",
       "      <td>[pinot-server-0, pinot-server-1, pinot-server-2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_segmentation_2__0__6__20210411T1646Z</th>\n",
       "      <td>[pinot-server-0, pinot-server-1, pinot-server-2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    REALTIME\n",
       "trips_segmentation_2__0__0__20210411T1645Z  [pinot-server-0, pinot-server-1, pinot-server-2]\n",
       "trips_segmentation_2__0__1__20210411T1646Z  [pinot-server-0, pinot-server-1, pinot-server-2]\n",
       "trips_segmentation_2__0__2__20210411T1646Z  [pinot-server-0, pinot-server-1, pinot-server-2]\n",
       "trips_segmentation_2__0__3__20210411T1646Z  [pinot-server-0, pinot-server-1, pinot-server-2]\n",
       "trips_segmentation_2__0__4__20210411T1646Z  [pinot-server-0, pinot-server-1, pinot-server-2]\n",
       "trips_segmentation_2__0__5__20210411T1646Z  [pinot-server-0, pinot-server-1, pinot-server-2]\n",
       "trips_segmentation_2__0__6__20210411T1646Z  [pinot-server-0, pinot-server-1, pinot-server-2]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(external_view_for_table_dataframe(\"trips_segmentation_1\"))\n",
    "display(external_view_for_table_dataframe(\"trips_segmentation_2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-mississippi",
   "metadata": {},
   "source": [
    "We can use the broker's debug endpoint to retrieve a routing table for a specific SQL query. This can be seen as a query execution plan for segments distributed across multiple servers. Similar to calculating an efficient query execution plan in classical RDBMSs, Pinot takes a look at metadata, statistics and server associations.\n",
    "The routing table might change everytime an identical query is executed, as brokers try to distribute compute load across servers hosting the same segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "owned-painting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "    SELECT driver_name, sum(count) AS trips_count\n",
      "    FROM trips_segmentation_1_REALTIME\n",
      "    WHERE trip_start_time_millis BETWEEN 1618159486495 AND 1618239458972\n",
      "    GROUP BY driver_name\n",
      "    ORDER BY trips_count desc\n",
      "    LIMIT 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>server</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trips_segmentation_1__0__0__20210411T1645Z</td>\n",
       "      <td>pinot-server-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trips_segmentation_1__0__1__20210411T1646Z</td>\n",
       "      <td>pinot-server-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trips_segmentation_1__0__2__20210411T1646Z</td>\n",
       "      <td>pinot-server-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trips_segmentation_1__0__3__20210411T1646Z</td>\n",
       "      <td>pinot-server-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      segment          server\n",
       "0  trips_segmentation_1__0__0__20210411T1645Z  pinot-server-1\n",
       "1  trips_segmentation_1__0__1__20210411T1646Z  pinot-server-1\n",
       "2  trips_segmentation_1__0__2__20210411T1646Z  pinot-server-1\n",
       "3  trips_segmentation_1__0__3__20210411T1646Z  pinot-server-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routing_table_for_query_dataframe(query_for_trips_segmentation_1.replace(\"trips_segmentation_1\", \"trips_segmentation_1_REALTIME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-graduate",
   "metadata": {},
   "source": [
    "For the second query, the routing table shows, that the broker will try to equally distribute load between all the servers, as the segments are replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "liberal-naples",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "    SELECT driver_name, avg(driver_rating) AS rating\n",
      "    FROM trips_segmentation_2_REALTIME\n",
      "    WHERE trip_start_time_millis BETWEEN 1618159486495 AND 1618309433532\n",
      "    GROUP BY driver_name\n",
      "    ORDER BY rating desc\n",
      "    LIMIT 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>server</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trips_segmentation_2__0__0__20210411T1645Z</td>\n",
       "      <td>pinot-server-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trips_segmentation_2__0__1__20210411T1646Z</td>\n",
       "      <td>pinot-server-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trips_segmentation_2__0__2__20210411T1646Z</td>\n",
       "      <td>pinot-server-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trips_segmentation_2__0__3__20210411T1646Z</td>\n",
       "      <td>pinot-server-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trips_segmentation_2__0__4__20210411T1646Z</td>\n",
       "      <td>pinot-server-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trips_segmentation_2__0__5__20210411T1646Z</td>\n",
       "      <td>pinot-server-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trips_segmentation_2__0__6__20210411T1646Z</td>\n",
       "      <td>pinot-server-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      segment          server\n",
       "0  trips_segmentation_2__0__0__20210411T1645Z  pinot-server-1\n",
       "1  trips_segmentation_2__0__1__20210411T1646Z  pinot-server-2\n",
       "2  trips_segmentation_2__0__2__20210411T1646Z  pinot-server-0\n",
       "3  trips_segmentation_2__0__3__20210411T1646Z  pinot-server-1\n",
       "4  trips_segmentation_2__0__4__20210411T1646Z  pinot-server-2\n",
       "5  trips_segmentation_2__0__5__20210411T1646Z  pinot-server-0\n",
       "6  trips_segmentation_2__0__6__20210411T1646Z  pinot-server-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routing_table_for_query_dataframe(query_for_trips_segmentation_2.replace(\"trips_segmentation_2\", \"trips_segmentation_2_REALTIME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-position",
   "metadata": {},
   "source": [
    "## Advanced Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-endorsement",
   "metadata": {},
   "source": [
    "The presented tables are rather simple and just demonstrate the basic mechanisms of segmentation, replication and query routing in Pinot. However, Pinot offers much more advanced configuration options for tweaking segment replication, availability and placement in large-scale Pinot clusters.\n",
    "\n",
    "For example, Pinot servers can be grouped in so called \"replica groups\", that can be spread across different availability zones. Segment replicas will then be assigned to servers in different replica groups in order to achieve high-availability setups. Furthermore, segments can be partitioned based on column values to further increase query performance by decreasing the number of segments that need to be processed for a given query. This is very similar to partitioning/sharding in typical RDBMSs.\n",
    "Additionally, servers can be assigned to different tenants for sharing a cluster across teams or grouped into server-pools to achieve no-downtime rolling restarts of large clusters.\n",
    "\n",
    "All of these options show, that segmentation in Pinot is in the simplest aspects quite comparable to sharding mechanism in other database systems, but it is also much more advanced to support large-scale analytical use-cases while maintaining high performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-idaho",
   "metadata": {},
   "source": [
    "# Batch Ingestion and Hybrid Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-atlanta",
   "metadata": {},
   "source": [
    "As mentioned earlier, Pinot also support ingesting data from batch processing jobs. For offline tables, the same principles apply as for realtime tables with regards to segmentation and query routing. \n",
    "Though, segments are compiled and packaged outside Pinot. For this purpose, Pinot offers different mechanisms to load pre-built segments from object stores (such as S3) or HDFS or to build new segments using Hadoop and/or Spark.\n",
    "Segments are packaged as gzipped tar-archives (including data, index maps, column statistics) and can be uploaded to and downloaded from the controller.\n",
    "\n",
    "While offline tables can be used standalone similar to the realtime tables presented above, a more interesting option is to combine an offline and a realtime table to form a hybrid table.\n",
    "Hybrid tables are comprised of two individual tables, one offline table and one hybrid table, both sharing the same name, schema and ‚Äì most importantly ‚Äì time column. The hybrid table can be queried just like any other table, but the broker will transparently rewrite queries to fetch older records from the offline table and newer records from the realtime table.\n",
    "This allows to process, deduplicate and sanitize records before pushing them to long-term storage. This is a key differentiator between Pinot and other databases and OLAP stores. It allows Pinot to achieve high-throughput ingestion, low-latency realtime analytics, while still allowing to backfill data in batch processing.\n",
    "\n",
    "Since version `0.6.0` Pinot also offers a mechanism to regularly move records from a realtime table to the corresponding offline table. To configure this, the user can schedule a task, which should be executed on a minion instance for example once every day. The task execution will then take over downloading, transforming, aggregating, sorting and uploading of segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incomplete-aurora",
   "metadata": {},
   "source": [
    "To demonstrate how batch ingestion and hybrid tables work in Pinot without setting up an external batch processing system or periodic segment transformation job, we're going to create a realtime table reading from our Kafka `trips` topic, download completed segments from the controller and re-upload them as offline segments.\n",
    "\n",
    "First, we need to create both tables (note the shared name and schema):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "literary-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common configuration used for both tables types\n",
    "table_config_template = {\n",
    "  \"tableName\": \"trips_hybrid\",\n",
    "  \"segmentsConfig\": {\n",
    "    \"timeColumnName\": \"trip_start_time_millis\",\n",
    "    \"timeType\": \"MILLISECONDS\",\n",
    "    \"retentionTimeUnit\": \"DAYS\",\n",
    "    \"retentionTimeValue\": \"60\",\n",
    "    \"schemaName\": \"trips\",\n",
    "    \"replication\": \"1\"\n",
    "  },\n",
    "  \"tenants\": {},\n",
    "  \"tableIndexConfig\": {\n",
    "    \"loadMode\": \"MMAP\",\n",
    "    \"invertedIndexColumns\": [\n",
    "        \"rider_name\",\n",
    "        \"driver_name\",\n",
    "        \"start_location\",\n",
    "        \"end_location\"\n",
    "    ]\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"customConfigs\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "excess-trick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Table trips_hybrid_OFFLINE succesfully added'}\n"
     ]
    }
   ],
   "source": [
    "# create offline table\n",
    "table_config = copy.deepcopy(table_config_template)\n",
    "table_config[\"tableType\"] = \"OFFLINE\"\n",
    "print(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "widespread-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Table trips_hybrid_REALTIME succesfully added'}\n"
     ]
    }
   ],
   "source": [
    "# create realtime table\n",
    "table_config = copy.deepcopy(table_config_template)\n",
    "table_config[\"tableType\"] = \"REALTIME\"\n",
    "table_config[\"segmentsConfig\"][\"replicasPerPartition\"] = \"1\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"] = {\n",
    "  \"streamType\": \"kafka\",\n",
    "  \"stream.kafka.consumer.type\": \"simple\",\n",
    "  \"stream.kafka.topic.name\": \"trips\",\n",
    "  \"stream.kafka.decoder.class.name\": \"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\",\n",
    "  \"stream.kafka.consumer.factory.class.name\": \"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\",\n",
    "  \"stream.kafka.zk.broker.url\": \"pinot-kafka-zookeeper:2181\",\n",
    "  \"stream.kafka.broker.list\": \"pinot-kafka:9092\",\n",
    "  \"realtime.segment.flush.threshold.time\": \"12h\",\n",
    "  \"realtime.segment.flush.threshold.size\": \"50000\",\n",
    "  \"stream.kafka.consumer.prop.auto.offset.reset\": \"smallest\"\n",
    "}\n",
    "print(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focal-dominant",
   "metadata": {},
   "source": [
    "Let's again wait for our table to finish loading the data from Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "specified-latex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for table trips_hybrid to finish loading (loaded 64873 docs)\n",
      "waiting for table trips_hybrid to finish loading (loaded 274981 docs)\n",
      "waiting for table trips_hybrid to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_hybrid finished, (loaded 309911 docs)--\n"
     ]
    }
   ],
   "source": [
    "wait_for_table_to_finish_loading(\"trips_hybrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-tackle",
   "metadata": {},
   "source": [
    "Let's take a look at the external view of the hybrid table before touching it. We can see some realtime segments, that were built from the data stream from Kafka, but there are no offline segments so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "floppy-yorkshire",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REALTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__0__20210411T1650Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__1__20210411T1650Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__2__20210411T1650Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__3__20210411T1650Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__4__20210411T1650Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__5__20210411T1650Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__6__20210411T1650Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            REALTIME\n",
       "trips_hybrid__0__0__20210411T1650Z  [pinot-server-1]\n",
       "trips_hybrid__0__1__20210411T1650Z  [pinot-server-1]\n",
       "trips_hybrid__0__2__20210411T1650Z  [pinot-server-1]\n",
       "trips_hybrid__0__3__20210411T1650Z  [pinot-server-1]\n",
       "trips_hybrid__0__4__20210411T1650Z  [pinot-server-1]\n",
       "trips_hybrid__0__5__20210411T1650Z  [pinot-server-1]\n",
       "trips_hybrid__0__6__20210411T1650Z  [pinot-server-1]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_view_for_table_dataframe(\"trips_hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "senior-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers for transforming realtime segments to offline segment\n",
    "tmp_hybrid_basedir = \"/tmp/trips_hybrid\"\n",
    "# cleanup old artifacts if any\n",
    "shutil.rmtree(tmp_hybrid_basedir, ignore_errors=True)\n",
    "os.mkdir(tmp_hybrid_basedir)\n",
    "\n",
    "def path_for_realtime_tar(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}.tar.gz\"\n",
    "\n",
    "def path_for_offline_dir(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}_offline\"\n",
    "\n",
    "def path_for_offline_tar(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}_offline.tar.gz\"\n",
    "\n",
    "def download_segment(segment_metadata):\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    download_url = segment_metadata[\"segment.realtime.download.url\"]\n",
    "    segment_realtime_tar = path_for_realtime_tar(segment_name)\n",
    "\n",
    "    # cleanup old downloads\n",
    "    try:\n",
    "        os.remove(segment_realtime_tar)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    # download realtime segment tar\n",
    "    response = requests.get(download_url, stream=True)\n",
    "    with open(segment_realtime_tar, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response.raw, out_file)\n",
    "    del response\n",
    "    \n",
    "    print(f\"segment {segment_name} downloaded from {download_url} to {segment_realtime_tar}\")\n",
    "    return segment_realtime_tar\n",
    "\n",
    "def untar_segment(segment_metadata):\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_basedir = path_for_offline_dir(segment_name)\n",
    "    segment_realtime_tar = path_for_realtime_tar(segment_name)\n",
    "\n",
    "    # cleanup old artifacts if any\n",
    "    shutil.rmtree(segment_offline_basedir, ignore_errors=True)\n",
    "\n",
    "    # extract downloaded segment tar\n",
    "    with tarfile.open(segment_realtime_tar, 'r:gz') as tar:\n",
    "        tar.extractall(path=segment_offline_basedir)\n",
    "\n",
    "    print(f\"segment {segment_name} untarred to {segment_offline_basedir}\")\n",
    "    return segment_offline_basedir\n",
    "\n",
    "def transform_segment(segment_metadata):\n",
    "    realtime_table_name = segment_metadata[\"segment.table.name\"]\n",
    "    offline_table_name = realtime_table_name.replace(\"REALTIME\", \"OFFLINE\")\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_basedir = path_for_offline_dir(segment_name)\n",
    "    \n",
    "    # modify metadata.properties of segment\n",
    "    segment_offline_dir = segment_offline_basedir + \"/\" + segment_name\n",
    "    metadata_file = segment_offline_dir + \"/v3/metadata.properties\"\n",
    "    metadata_contents = None\n",
    "    with open(metadata_file, 'r') as file:\n",
    "      metadata_contents = file.read()\n",
    "    \n",
    "    metadata_contents = metadata_contents.replace(realtime_table_name, offline_table_name)\n",
    "    \n",
    "    with open(metadata_file, 'w') as file:\n",
    "      file.write(metadata_contents)\n",
    "    del metadata_contents\n",
    "\n",
    "    # create new offline segment tar\n",
    "    segment_offline_tar = path_for_offline_tar(segment_name)\n",
    "    with tarfile.open(segment_offline_tar, 'w:gz') as tar:\n",
    "        tar.add(segment_offline_dir, arcname=segment_name)\n",
    "\n",
    "    print(f\"segment {segment_name} transformed to offline segment to {segment_offline_tar}\")\n",
    "    return segment_offline_tar\n",
    "\n",
    "def upload_segment_to_offline_table(segment_metadata):\n",
    "    realtime_table_name = segment_metadata[\"segment.table.name\"]\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_tar = path_for_offline_tar(segment_name)\n",
    "    table_name = realtime_table_name.replace(\"_REALTIME\", \"_OFFLINE\")\n",
    "    \n",
    "    # POST segment as multipart/form-data for key 'segment'\n",
    "    with open(segment_offline_tar, 'rb') as tar:\n",
    "        response = requests.post(f'http://pinot-controller.pinot:9000/v2/segments?table={table_name}', files={\n",
    "            'segment': tar\n",
    "        })\n",
    "        print(response)\n",
    "        print(response.json())\n",
    "\n",
    "def transform_and_upload_nth_segment_to_offline_table(segment_metadata, n):\n",
    "    nth_meta = segment_metadata_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\")\n",
    "    \n",
    "    # download, transform and upload all in one row\n",
    "    download_segment(nth_meta)\n",
    "    untar_segment(nth_meta)\n",
    "    transform_segment(nth_meta)\n",
    "    upload_segment_to_offline_table(nth_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-neutral",
   "metadata": {},
   "source": [
    "Now, we fetch the first two segments from the controller, manipulate the metadata and re-upload them to the controller as offline segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "finite-prime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segment trips_hybrid__0__0__20210411T1650Z downloaded from http://pinot-controller-0.pinot-controller-headless.pinot.svc.cluster.local:9000/segments/trips_hybrid/trips_hybrid__0__0__20210411T1650Z to /tmp/trips_hybrid/trips_hybrid__0__0__20210411T1650Z.tar.gz\n",
      "segment trips_hybrid__0__0__20210411T1650Z untarred to /tmp/trips_hybrid/trips_hybrid__0__0__20210411T1650Z_offline\n",
      "segment trips_hybrid__0__0__20210411T1650Z transformed to offline segment to /tmp/trips_hybrid/trips_hybrid__0__0__20210411T1650Z_offline.tar.gz\n",
      "<Response [200]>\n",
      "{'status': 'Successfully uploaded segment: trips_hybrid__0__0__20210411T1650Z of table: trips_hybrid_OFFLINE'}\n",
      "segment trips_hybrid__0__1__20210411T1650Z downloaded from http://pinot-controller-0.pinot-controller-headless.pinot.svc.cluster.local:9000/segments/trips_hybrid/trips_hybrid__0__1__20210411T1650Z to /tmp/trips_hybrid/trips_hybrid__0__1__20210411T1650Z.tar.gz\n",
      "segment trips_hybrid__0__1__20210411T1650Z untarred to /tmp/trips_hybrid/trips_hybrid__0__1__20210411T1650Z_offline\n",
      "segment trips_hybrid__0__1__20210411T1650Z transformed to offline segment to /tmp/trips_hybrid/trips_hybrid__0__1__20210411T1650Z_offline.tar.gz\n",
      "<Response [200]>\n",
      "{'status': 'Successfully uploaded segment: trips_hybrid__0__1__20210411T1650Z of table: trips_hybrid_OFFLINE'}\n"
     ]
    }
   ],
   "source": [
    "segment_metadata_hybrid = segment_metadata_for_table(\"trips_hybrid\")\n",
    "\n",
    "transform_and_upload_nth_segment_to_offline_table(segment_metadata_hybrid, 0)\n",
    "transform_and_upload_nth_segment_to_offline_table(segment_metadata_hybrid, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-dodge",
   "metadata": {},
   "source": [
    "The external view for our hybrid table now shows the newly added offline segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "efficient-symposium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OFFLINE</th>\n",
       "      <th>REALTIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__0__20210411T1650Z</th>\n",
       "      <td>[pinot-server-0]</td>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__1__20210411T1650Z</th>\n",
       "      <td>[pinot-server-1]</td>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__2__20210411T1650Z</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__3__20210411T1650Z</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__4__20210411T1650Z</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__5__20210411T1650Z</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_hybrid__0__6__20210411T1650Z</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[pinot-server-1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             OFFLINE          REALTIME\n",
       "trips_hybrid__0__0__20210411T1650Z  [pinot-server-0]  [pinot-server-1]\n",
       "trips_hybrid__0__1__20210411T1650Z  [pinot-server-1]  [pinot-server-1]\n",
       "trips_hybrid__0__2__20210411T1650Z               NaN  [pinot-server-1]\n",
       "trips_hybrid__0__3__20210411T1650Z               NaN  [pinot-server-1]\n",
       "trips_hybrid__0__4__20210411T1650Z               NaN  [pinot-server-1]\n",
       "trips_hybrid__0__5__20210411T1650Z               NaN  [pinot-server-1]\n",
       "trips_hybrid__0__6__20210411T1650Z               NaN  [pinot-server-1]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_view_for_table_dataframe(\"trips_hybrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-cleaning",
   "metadata": {},
   "source": [
    "This example query lists the top 5 riders in terms of total trip time. It shows that hybrid tables can be queried in the exact same way, as realtime tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "experienced-lawrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: \n",
      "    SELECT rider_name, sum(trip_end_time_millis - trip_start_time_millis) / (60*60*1000) AS trip_time_sum\n",
      "    FROM trips_hybrid\n",
      "    GROUP BY rider_name\n",
      "    ORDER BY trip_time_sum DESC\n",
      "    LIMIT 5\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rider_name</th>\n",
       "      <th>trip_time_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice Reese</td>\n",
       "      <td>6035.993905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dennis Smith</td>\n",
       "      <td>5864.333590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rodney Jones</td>\n",
       "      <td>3620.798730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Debbie Miller</td>\n",
       "      <td>3590.483984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mary Franco</td>\n",
       "      <td>3545.339102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      rider_name  trip_time_sum\n",
       "0    Alice Reese    6035.993905\n",
       "1   Dennis Smith    5864.333590\n",
       "2   Rodney Jones    3620.798730\n",
       "3  Debbie Miller    3590.483984\n",
       "4    Mary Franco    3545.339102"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_for_hybrid = \"\"\"\n",
    "    SELECT rider_name, sum(trip_end_time_millis - trip_start_time_millis) / (60*60*1000) AS trip_time_sum\n",
    "    FROM trips_hybrid\n",
    "    GROUP BY rider_name\n",
    "    ORDER BY trip_time_sum DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "\n",
    "query_result = query_sql(query_for_hybrid)\n",
    "query_result_to_dataframe(query_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-composite",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-chart",
   "metadata": {},
   "source": [
    "## Table Creation with Different Indexing Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-inside",
   "metadata": {},
   "source": [
    "To demonstrate the different indexing options and mechanisms, that Pinot offers, we will create some tables with different index configurations, describe their key properties and compare query performance.\n",
    "The index configurations are applied to the `tableIndexConfig`-section the table configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "juvenile-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{\"status\":\"Table trips_default_index_REALTIME succesfully added\"}\n",
      "<Response [200]>\n",
      "{\"status\":\"Table trips_rawForwardIndex_REALTIME succesfully added\"}\n",
      "<Response [200]>\n",
      "{\"status\":\"Table trips_sortedForwardIndex_REALTIME succesfully added\"}\n",
      "<Response [200]>\n",
      "{\"status\":\"Table trips_bitmapInvertedIndex_startLocation_REALTIME succesfully added\"}\n",
      "<Response [200]>\n",
      "{\"status\":\"Table trips_sortedInvertedIndex_startLocation_REALTIME succesfully added\"}\n",
      "<Response [200]>\n",
      "{\"status\":\"Table trips_starTreeIndex_REALTIME succesfully added\"}\n",
      "<Response [200]>\n",
      "{\"status\":\"Table trips_textIndex_REALTIME succesfully added\"}\n"
     ]
    }
   ],
   "source": [
    "# Array to collect details of created tables\n",
    "table_list = []\n",
    "\n",
    "table_config_template = {\n",
    "  \"tableType\": \"REALTIME\",\n",
    "  \"segmentsConfig\": {\n",
    "    \"timeColumnName\": \"trip_start_time_millis\",\n",
    "    \"timeType\": \"MILLISECONDS\",\n",
    "    \"retentionTimeUnit\": \"DAYS\",\n",
    "    \"retentionTimeValue\": \"60\",\n",
    "    \"schemaName\": \"trips\",\n",
    "    \"replication\": \"1\",\n",
    "    \"replicasPerPartition\": \"1\"\n",
    "  },\n",
    "  \"tenants\": {},\n",
    "  \"tableIndexConfig\": {\n",
    "    \"loadMode\": \"MMAP\",\n",
    "    \"streamConfigs\": {\n",
    "      \"streamType\": \"kafka\",\n",
    "      \"stream.kafka.consumer.type\": \"simple\",\n",
    "      \"stream.kafka.topic.name\": \"trips\",\n",
    "      \"stream.kafka.decoder.class.name\": \"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\",\n",
    "      \"stream.kafka.consumer.factory.class.name\": \"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\",\n",
    "      \"stream.kafka.zk.broker.url\": \"pinot-kafka-zookeeper:2181\",\n",
    "      \"stream.kafka.broker.list\": \"pinot-kafka:9092\",\n",
    "      \"realtime.segment.flush.threshold.time\": \"12h\",\n",
    "      \"realtime.segment.flush.threshold.size\": \"20000\",\n",
    "      \"stream.kafka.consumer.prop.auto.offset.reset\": \"smallest\"\n",
    "    }\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"customConfigs\": {}\n",
    "  }\n",
    "} \n",
    "\n",
    "# helper function\n",
    "def createTable(newTable_name, index_text, tableconfig_json):\n",
    "    # Input: Name of new table, index description, table configuration in json structure\n",
    "    response = requests.post('http://pinot-controller.pinot:9000/tables', json=tableconfig_json)\n",
    "    print(response)\n",
    "    print(response.text)\n",
    "    table_list.append([newTable_name, index_text])\n",
    "\n",
    "\n",
    "execution_start_time = int(round(time.time() * 1000))\n",
    "\n",
    "# Create a new table with default index for each column (no configuration required)\n",
    "newTable_defaultIndex = copy.deepcopy(table_config_template)\n",
    "newTable_defaultIndex[\"tableName\"] = \"trips_default_index\"\n",
    "createTable(newTable_defaultIndex[\"tableName\"], 'Default Index (Dictionary-encoded forward index with bit compression) for each column', newTable_defaultIndex)\n",
    "\n",
    "# Create a new table with raw value forward index\n",
    "newTable_rawForwardIndex = copy.deepcopy(table_config_template)\n",
    "newTable_rawForwardIndex[\"tableName\"] = \"trips_rawForwardIndex\"\n",
    "newTable_rawForwardIndex[\"tableIndexConfig\"][\"noDictionaryColumns\"] = [\"start_location\"]\n",
    "createTable(newTable_rawForwardIndex[\"tableName\"], 'Raw value forward index on start_location', newTable_rawForwardIndex)\n",
    "\n",
    "# Create a new table with sorted forward index with run-length encoding\n",
    "newTable_sortedForwardIndex = copy.deepcopy(table_config_template)\n",
    "newTable_sortedForwardIndex[\"tableName\"] = \"trips_sortedForwardIndex\"\n",
    "newTable_sortedForwardIndex[\"tableIndexConfig\"][\"sortedColumn\"] = [\"start_location\"]\n",
    "createTable(newTable_sortedForwardIndex[\"tableName\"], 'Sorted forward index with run-length encoding on start location', newTable_sortedForwardIndex)\n",
    "\n",
    "# Create a new table with bitmap inverted index\n",
    "newTable_bitmapInvertedIndex = copy.deepcopy(table_config_template)\n",
    "newTable_bitmapInvertedIndex[\"tableName\"] = \"trips_bitmapInvertedIndex_startLocation\"\n",
    "newTable_bitmapInvertedIndex[\"tableIndexConfig\"][\"invertedIndexColumns\"] = [\"start_location\"]\n",
    "createTable(newTable_bitmapInvertedIndex[\"tableName\"], 'Bitmap inverted index on start_location', newTable_bitmapInvertedIndex)\n",
    "\n",
    "# Create a new table with sorted inverted index\n",
    "newTable_sortedInvertedIndex = copy.deepcopy(table_config_template)\n",
    "newTable_sortedInvertedIndex[\"tableName\"] = \"trips_sortedInvertedIndex_startLocation\"\n",
    "newTable_sortedInvertedIndex[\"tableIndexConfig\"][\"invertedIndexColumns\"] = [\"start_location\"]\n",
    "newTable_sortedInvertedIndex[\"tableIndexConfig\"][\"sortedColumn\"] = [\"start_location\"]\n",
    "createTable(newTable_sortedInvertedIndex[\"tableName\"], 'Sorted inverted index on start_location', newTable_sortedInvertedIndex)\n",
    "\n",
    "# Create a new table with star tree index\n",
    "newTable_starTree = copy.deepcopy(table_config_template)\n",
    "newTable_starTree[\"tableName\"] = \"trips_starTreeIndex\"\n",
    "newTable_starTree[\"tableIndexConfig\"][\"starTreeIndexConfigs\"] = [{\n",
    "    \"dimensionsSplitOrder\": [\n",
    "      \"rider_is_premium\",\n",
    "      \"start_location_state\",\n",
    "      \"end_location\"\n",
    "    ],\n",
    "    \"functionColumnPairs\": [\n",
    "      \"SUM__payment_amount\",\n",
    "    ],\n",
    "    \"maxLeafRecords\": 1\n",
    "  }]\n",
    "createTable(newTable_starTree[\"tableName\"], 'Star Tree', newTable_starTree)\n",
    "\n",
    "# Create a new table with text index\n",
    "newTable_textIndex = copy.deepcopy(table_config_template)\n",
    "newTable_textIndex[\"tableName\"] = \"trips_textIndex\"\n",
    "newTable_textIndex[\"fieldConfigList\"]= [\n",
    "  {\n",
    "     \"name\":\"driver_name\",\n",
    "     \"encodingType\":\"RAW\",\n",
    "     \"indexType\":\"TEXT\"\n",
    "  },\n",
    "  {\n",
    "     \"name\":\"rider_name\",\n",
    "     \"encodingType\":\"RAW\",\n",
    "     \"indexType\":\"TEXT\"\n",
    "  }\n",
    "]\n",
    "newTable_textIndex[\"tableIndexConfig\"][\"noDictionaryColumns\"] = [\n",
    "     \"driver_name\",\n",
    "     \"rider_name\"\n",
    " ]\n",
    "createTable(newTable_textIndex[\"tableName\"], 'Text Index', newTable_textIndex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-superior",
   "metadata": {},
   "source": [
    "All created tables consume data from the same Kafka topic (`trips`). Therefore, all of them will contain the same data records.\n",
    "To ensure, that the consumption of the tables has finished before executing queries, we use the helper function from above to wait until the tables have finished loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "prescription-prior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for table trips_starTreeIndex to finish loading (loaded 20000 docs)\n",
      "waiting for table trips_starTreeIndex to finish loading (loaded 60000 docs)\n",
      "waiting for table trips_starTreeIndex to finish loading (loaded 87123 docs)\n",
      "waiting for table trips_starTreeIndex to finish loading (loaded 120000 docs)\n",
      "waiting for table trips_starTreeIndex to finish loading (loaded 160000 docs)\n",
      "waiting for table trips_starTreeIndex to finish loading (loaded 200000 docs)\n",
      "waiting for table trips_starTreeIndex to finish loading (loaded 240000 docs)\n",
      "waiting for table trips_starTreeIndex to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_starTreeIndex finished, (loaded 309911 docs)--\n",
      "waiting for table trips_default_index to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_default_index finished, (loaded 309911 docs)--\n",
      "waiting for table trips_rawForwardIndex to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_rawForwardIndex finished, (loaded 309911 docs)--\n",
      "waiting for table trips_sortedForwardIndex to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_sortedForwardIndex finished, (loaded 309911 docs)--\n",
      "waiting for table trips_bitmapInvertedIndex_startLocation to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_bitmapInvertedIndex_startLocation finished, (loaded 309911 docs)--\n",
      "waiting for table trips_sortedInvertedIndex_startLocation to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_sortedInvertedIndex_startLocation finished, (loaded 309911 docs)--\n",
      "waiting for table trips_textIndex to finish loading (loaded 309911 docs)\n",
      "--Consumption of generated data for table trips_textIndex finished, (loaded 309911 docs)--\n"
     ]
    }
   ],
   "source": [
    "# star-tree index building takes some time (longer than other tables), wait for it first\n",
    "wait_for_table_to_finish_loading(\"trips_starTreeIndex\")\n",
    "\n",
    "for table in table_list:\n",
    "    table_name = table[0]\n",
    "    if table_name == \"trips_starTreeIndex\":\n",
    "        continue\n",
    "    wait_for_table_to_finish_loading(table_name, wait_time=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "relative-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: SELECT start_location, driver_name FROM trips_default_index LIMIT 1\n",
      "Using 'Emden' as start location and 'Michael' as driver name for upcoming queries.\n"
     ]
    }
   ],
   "source": [
    "# Read first start location and first driver name to use it as variables in upcoming queries\n",
    "query_result = query_sql(f\"SELECT start_location, driver_name FROM trips_default_index LIMIT 1\")\n",
    "\n",
    "startLocation = query_result['resultTable']['rows'][0][0]\n",
    "# Read the first name of the driver name\n",
    "driverName = (query_result['resultTable']['rows'][0][1]).split()[0]       \n",
    "\n",
    "print(f\"Using '{startLocation}' as start location and '{driverName}' as driver name for upcoming queries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-trail",
   "metadata": {},
   "source": [
    "## Table Size\n",
    "\n",
    "Although all tables contain the same amount of records and also the same record values, the table size differs.\n",
    "This is because of the different indexes used. E.g. a text index on two columns consumes much more space compared to the raw forward index. The Star-Tree index is allocating the most disk space, as Pinot materializes pre-aggregations for calculations on defined metric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "optional-cradle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>reportedSizeInMB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trips_default_index_REALTIME</th>\n",
       "      <td>Default Index (Dictionary-encoded forward index with bit compression) for each column</td>\n",
       "      <td>22.197715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_rawForwardIndex_REALTIME</th>\n",
       "      <td>Raw value forward index on start_location</td>\n",
       "      <td>24.548973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_sortedForwardIndex_REALTIME</th>\n",
       "      <td>Sorted forward index with run-length encoding on start location</td>\n",
       "      <td>20.196658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_bitmapInvertedIndex_startLocation_REALTIME</th>\n",
       "      <td>Bitmap inverted index on start_location</td>\n",
       "      <td>23.044106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_sortedInvertedIndex_startLocation_REALTIME</th>\n",
       "      <td>Sorted inverted index on start_location</td>\n",
       "      <td>20.197087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_starTreeIndex_REALTIME</th>\n",
       "      <td>Star Tree</td>\n",
       "      <td>39.42692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trips_textIndex_REALTIME</th>\n",
       "      <td>Text Index</td>\n",
       "      <td>36.26193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                            description  \\\n",
       "trips_default_index_REALTIME                      Default Index (Dictionary-encoded forward index with bit compression) for each column   \n",
       "trips_rawForwardIndex_REALTIME                                                                Raw value forward index on start_location   \n",
       "trips_sortedForwardIndex_REALTIME                                       Sorted forward index with run-length encoding on start location   \n",
       "trips_bitmapInvertedIndex_startLocation_REALTIME                                                Bitmap inverted index on start_location   \n",
       "trips_sortedInvertedIndex_startLocation_REALTIME                                                Sorted inverted index on start_location   \n",
       "trips_starTreeIndex_REALTIME                                                                                                  Star Tree   \n",
       "trips_textIndex_REALTIME                                                                                                     Text Index   \n",
       "\n",
       "                                                 reportedSizeInMB  \n",
       "trips_default_index_REALTIME                            22.197715  \n",
       "trips_rawForwardIndex_REALTIME                          24.548973  \n",
       "trips_sortedForwardIndex_REALTIME                       20.196658  \n",
       "trips_bitmapInvertedIndex_startLocation_REALTIME        23.044106  \n",
       "trips_sortedInvertedIndex_startLocation_REALTIME        20.197087  \n",
       "trips_starTreeIndex_REALTIME                             39.42692  \n",
       "trips_textIndex_REALTIME                                 36.26193  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_size_data = {}\n",
    "\n",
    "for table in table_list:\n",
    "    response = requests.get(f'http://pinot-controller.pinot:9000/tables/{table[0]}_REALTIME/size?detailed=false').json()\n",
    "    table_name = response['tableName']\n",
    "    table_size_data[table_name] = {\"description\": table[1], \"reportedSizeInMB\": response['reportedSizeInBytes']/1024/1024}\n",
    "\n",
    "pd.set_option('max_colwidth', 400)\n",
    "display(pd.DataFrame(table_size_data).transpose())\n",
    "pd.reset_option('max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-fellow",
   "metadata": {},
   "source": [
    "## Comparison of Indexing Options\n",
    "\n",
    "The function `executeSQLStatement` takes a query string and an array containing table names and index descriptions as input parameters. It executes the query on all tables which are defined in the array `table_list`. If `specific_tables_array` is empty, the query will be executed on all tables which have been created for this chapter. The top two records of the result data set are displayed once to get an insight into the result. Additionally, the function will create a `DataFrame` listing query execution statistics for each table. Metrics of one query execution will only be appended to the `DataFrame` if no exception occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cathedral-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeSQLStatement(sql_statement_with_variable, specific_tables_array):\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    df_metrics = pd.DataFrame(columns=['indextype','table', 'numDocsScanned',\n",
    "       'numEntriesScannedInFilter', 'numEntriesScannedPostFilter',\n",
    "       'totalDocs', 'timeUsedMs',\n",
    "       'minConsumingFreshnessTimeMs',\n",
    "       'exceptions'])\n",
    "    b_resultRecordsNotShown = True;\n",
    "    if not specific_tables_array:\n",
    "        table_list_statement = table_list\n",
    "    else:\n",
    "        table_list_statement = specific_tables_array \n",
    "    for table in table_list_statement:\n",
    "    \n",
    "        sql_statement = sql_statement_with_variable.replace(\"XX_TABLE\",table[0])\n",
    "        sql_statement = sql_statement.replace(\"XX_STARTLOCATION\",\"'\"+startLocation+\"'\")\n",
    "        sql_statement = sql_statement.replace(\"XX_DRIVERNAME\",\"'\"+driverName+\"'\") \n",
    "        response = requests.post('http://pinot-broker.pinot:8099/query/sql', json={\n",
    "            \"sql\" : sql_statement\n",
    "        })\n",
    "        response_json=response.json()\n",
    "        d = {'indextype': table[1], 'table': table[0],'numDocsScanned': [response_json['numDocsScanned']],'numDocsScanned': [response_json['numDocsScanned']],'numEntriesScannedInFilter': [response_json['numEntriesScannedInFilter']], 'numEntriesScannedPostFilter':[response_json['numEntriesScannedPostFilter']],'totalDocs':[response_json['totalDocs']],'timeUsedMs':[response_json['timeUsedMs']],'minConsumingFreshnessTimeMs':[response_json['minConsumingFreshnessTimeMs']],'exceptions':[response_json['exceptions']]}\n",
    "        df_metrics_new = pd.DataFrame(data=d)\n",
    "        if not response_json['exceptions']:\n",
    "             df_metrics = df_metrics.append(df_metrics_new,ignore_index=True)\n",
    "       \n",
    "\n",
    "        if b_resultRecordsNotShown:\n",
    "            try:\n",
    "                if not response_json['exceptions']:\n",
    "                    columnNames = response_json['resultTable']['dataSchema']['columnNames']\n",
    "                    rows = response_json['resultTable']['rows']\n",
    "\n",
    "                    result_dataframe = pd.DataFrame(columns=columnNames,data=rows)\n",
    "                    print(\"Top two result records of: \" + sql_statement)\n",
    "                    display(result_dataframe.head(2))\n",
    "                    b_resultRecordsNotShown = False\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    display(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-cleaner",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "The main metrics of a query execution we will check are:\n",
    "- __timeUsedMs__: Total time between broker receiving the query request request and sending the response back to the client.\n",
    "- __numDocScanned__: Number of documents/records scanned while query processing. (Includes records scanned in the filter phase as well as after applying the filter.)\n",
    "- __numEntriesScannedInFilter__: It is an indicator of the latency contributed by the lookup phase. If this number is high, applying an index on the selection criteria might improve performance, especially if the selection criteria is highly selective.\n",
    "- __numEntriesScannedPostFilter__: High number is an indicator for low selectivity. Instead of regular indices, a star-tree index could help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupational-fairy",
   "metadata": {},
   "source": [
    "### Index Types\n",
    "\n",
    "For the tables create above, we configured the following index types:\n",
    "\n",
    "__Forward Index__\n",
    "- __Default Index: Dictionary-encoded forward index with bit compression__: \n",
    "    Apache Pinot will use this index by default for each column if no other index is configured in the table configuration. An id is assigned to each distinct value of the column, afterwards a dictionary is built matching an id to the value. In the forward index, only the bit-compressed id is persisted instead of the values. This compression improves space efficiency of the storage, if there are only a few distinct values.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/timebertt/adm-pinot/master/images/MarkdownTable_DefaultIndex.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-captain",
   "metadata": {},
   "source": [
    "- __Raw Value Forward Index__: A raw value forward index is configured as a `noDictionaryColumn` in the table configuration. Instead of dictionary ids, the raw values will be stored in columns. Because of that, no dictionary lookup is required and due to the locality of values the performance of scanning large number of values is improved. \n",
    "- __Sorted forward index with run-length encoding__: The sorted forward index is applied on top of the dictionary-encoding. For each dictionary id, a start and end document id is stored. Only one sorted column can be configured per table.\n",
    "   \n",
    "__Inverted Index__: Inverted Indexes reduce the number of records which need be processed by identifying the ones which contain the search term. The inverted index is created by selecting all distinct values of a given column. For each value, a list of document ids which contain the value will be stored. If we search e.g. for \"Hessen\" as a state, we can look up the inverted index for \"Hessen\" and identify the documents in which that value appears. \n",
    "- __Bitmap inverted index__: A map from each value to a bitmap is maintained for the column which is enabled as bitmap inverted index (e.g. \"Th√ºringen\" -> `Doc5, Doc1`). If a column is used frequently for filtering, an inverted index will improve the performance. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/timebertt/adm-pinot/master/images/MarkdownTable_BitmapInvertedIndex.png\" width=\"35%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-hindu",
   "metadata": {},
   "source": [
    "- __Sorted inverted index__: A sorted index can benefit from data locality, but can only be applied to one column.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/timebertt/adm-pinot/master/images/MarkdownTable_SortedInvertedIndex.png\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-peninsula",
   "metadata": {},
   "source": [
    "- __Star-Tree Index__: This index is built on multiple columns and pre-aggregates results per configured dimension hierarchy level, so that less values need to be processed. This can significantly improve query performance for hierarchical data (e.g. groups of users, workspaces, or states of locations in the `trips` example), on the other hand pre-aggregation requires also more disk space (table size can easily grow about twice of the size as the other tables).\n",
    "- __Text Index__: Text Indexes in Pinot allow to do aribtrary search on `STRING` columns (full text search)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-nightlife",
   "metadata": {},
   "source": [
    "#### Default Index (Dictionary-encoded forward index with bit compression) vs Raw value forward index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "common-builder",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top two result records of: select count, driver_name, driver_rating, end_location, end_location_state from trips_default_index WHERE start_location='Emden' LIMIT 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>driver_name</th>\n",
       "      <th>driver_rating</th>\n",
       "      <th>end_location</th>\n",
       "      <th>end_location_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Michael Weston</td>\n",
       "      <td>4</td>\n",
       "      <td>Laucha</td>\n",
       "      <td>Th√ºringen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Courtney Gonzalez</td>\n",
       "      <td>1</td>\n",
       "      <td>Gummersbach</td>\n",
       "      <td>Nordrhein-Westfalen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count        driver_name  driver_rating end_location   end_location_state\n",
       "0      1     Michael Weston              4       Laucha            Th√ºringen\n",
       "1      1  Courtney Gonzalez              1  Gummersbach  Nordrhein-Westfalen"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indextype</th>\n",
       "      <th>table</th>\n",
       "      <th>numDocsScanned</th>\n",
       "      <th>numEntriesScannedInFilter</th>\n",
       "      <th>numEntriesScannedPostFilter</th>\n",
       "      <th>totalDocs</th>\n",
       "      <th>timeUsedMs</th>\n",
       "      <th>minConsumingFreshnessTimeMs</th>\n",
       "      <th>exceptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default Index (Dictionary-encoded forward index with bit compression) for each column</td>\n",
       "      <td>trips_default_index</td>\n",
       "      <td>316</td>\n",
       "      <td>309911</td>\n",
       "      <td>1580</td>\n",
       "      <td>309911</td>\n",
       "      <td>96</td>\n",
       "      <td>1618160041688</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raw value forward index on start_location</td>\n",
       "      <td>trips_rawForwardIndex</td>\n",
       "      <td>316</td>\n",
       "      <td>309911</td>\n",
       "      <td>1580</td>\n",
       "      <td>309911</td>\n",
       "      <td>163</td>\n",
       "      <td>1618160038818</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               indextype  \\\n",
       "0  Default Index (Dictionary-encoded forward index with bit compression) for each column   \n",
       "1                                              Raw value forward index on start_location   \n",
       "\n",
       "                   table numDocsScanned numEntriesScannedInFilter  \\\n",
       "0    trips_default_index            316                    309911   \n",
       "1  trips_rawForwardIndex            316                    309911   \n",
       "\n",
       "  numEntriesScannedPostFilter totalDocs timeUsedMs  \\\n",
       "0                        1580    309911         96   \n",
       "1                        1580    309911        163   \n",
       "\n",
       "  minConsumingFreshnessTimeMs exceptions  \n",
       "0               1618160041688         []  \n",
       "1               1618160038818         []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "executeSQLStatement(\"select count, driver_name, driver_rating, end_location, end_location_state from XX_TABLE WHERE start_location=XX_STARTLOCATION LIMIT 10000\",[['trips_default_index', 'Default Index (Dictionary-encoded forward index with bit compression) for each column'],['trips_rawForwardIndex', 'Raw value forward index on start_location']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-northern",
   "metadata": {},
   "source": [
    "The query execution on table `trips_rawForwardIndex` takes more time. The main difference between the two index types is, that the index on column `start_location` of `trips_default_index` creates a dictionary. This dictionary provides compression when values of the columns occurr repeatedly. \n",
    "A dictionary index can't provide this advantage over the other index, if the column values have a high cardinality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-grave",
   "metadata": {},
   "source": [
    "#### Default Index (Dictionary-encoded forward index with bit compression) vs Sorted forward index with run-length encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "short-discount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top two result records of: select * from trips_default_index WHERE start_location='Emden' LIMIT 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>driver_name</th>\n",
       "      <th>driver_rating</th>\n",
       "      <th>end_location</th>\n",
       "      <th>end_location_state</th>\n",
       "      <th>end_zip_code</th>\n",
       "      <th>license_plate</th>\n",
       "      <th>payment_amount</th>\n",
       "      <th>payment_tip_amount</th>\n",
       "      <th>request_time_millis</th>\n",
       "      <th>rider_is_premium</th>\n",
       "      <th>rider_name</th>\n",
       "      <th>rider_rating</th>\n",
       "      <th>start_location</th>\n",
       "      <th>start_location_state</th>\n",
       "      <th>start_zip_code</th>\n",
       "      <th>trip_end_time_millis</th>\n",
       "      <th>trip_start_time_millis</th>\n",
       "      <th>trip_wait_time_millis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Michael Weston</td>\n",
       "      <td>4</td>\n",
       "      <td>Laucha</td>\n",
       "      <td>Th√ºringen</td>\n",
       "      <td>99880</td>\n",
       "      <td>CT-SC-79</td>\n",
       "      <td>906.81</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1618439397147</td>\n",
       "      <td>1</td>\n",
       "      <td>Jeremiah Santana</td>\n",
       "      <td>5</td>\n",
       "      <td>Emden</td>\n",
       "      <td>Niedersachsen</td>\n",
       "      <td>26725</td>\n",
       "      <td>1618473364124</td>\n",
       "      <td>1618440571397</td>\n",
       "      <td>1174250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Courtney Gonzalez</td>\n",
       "      <td>1</td>\n",
       "      <td>Gummersbach</td>\n",
       "      <td>Nordrhein-Westfalen</td>\n",
       "      <td>51643</td>\n",
       "      <td>MY-MD-47</td>\n",
       "      <td>270.84</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1618440921125</td>\n",
       "      <td>1</td>\n",
       "      <td>Patricia Stone</td>\n",
       "      <td>1</td>\n",
       "      <td>Emden</td>\n",
       "      <td>Niedersachsen</td>\n",
       "      <td>26725</td>\n",
       "      <td>1618455371860</td>\n",
       "      <td>1618443393678</td>\n",
       "      <td>2472553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count        driver_name  driver_rating end_location   end_location_state  \\\n",
       "0      1     Michael Weston              4       Laucha            Th√ºringen   \n",
       "1      1  Courtney Gonzalez              1  Gummersbach  Nordrhein-Westfalen   \n",
       "\n",
       "  end_zip_code license_plate  payment_amount  payment_tip_amount  \\\n",
       "0        99880      CT-SC-79          906.81                25.0   \n",
       "1        51643      MY-MD-47          270.84                 5.0   \n",
       "\n",
       "   request_time_millis  rider_is_premium        rider_name  rider_rating  \\\n",
       "0        1618439397147                 1  Jeremiah Santana             5   \n",
       "1        1618440921125                 1    Patricia Stone             1   \n",
       "\n",
       "  start_location start_location_state start_zip_code  trip_end_time_millis  \\\n",
       "0          Emden        Niedersachsen          26725         1618473364124   \n",
       "1          Emden        Niedersachsen          26725         1618455371860   \n",
       "\n",
       "   trip_start_time_millis  trip_wait_time_millis  \n",
       "0           1618440571397                1174250  \n",
       "1           1618443393678                2472553  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indextype</th>\n",
       "      <th>table</th>\n",
       "      <th>numDocsScanned</th>\n",
       "      <th>numEntriesScannedInFilter</th>\n",
       "      <th>numEntriesScannedPostFilter</th>\n",
       "      <th>totalDocs</th>\n",
       "      <th>timeUsedMs</th>\n",
       "      <th>minConsumingFreshnessTimeMs</th>\n",
       "      <th>exceptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default Index (Dictionary-encoded forward index with bit compression) for each column</td>\n",
       "      <td>trips_default_index</td>\n",
       "      <td>316</td>\n",
       "      <td>309911</td>\n",
       "      <td>6004</td>\n",
       "      <td>309911</td>\n",
       "      <td>65</td>\n",
       "      <td>1618160041688</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sorted forward index with run-length encoding on start location</td>\n",
       "      <td>trips_sortedForwardIndex</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>6004</td>\n",
       "      <td>309911</td>\n",
       "      <td>51</td>\n",
       "      <td>1618160039711</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               indextype  \\\n",
       "0  Default Index (Dictionary-encoded forward index with bit compression) for each column   \n",
       "1                        Sorted forward index with run-length encoding on start location   \n",
       "\n",
       "                      table numDocsScanned numEntriesScannedInFilter  \\\n",
       "0       trips_default_index            316                    309911   \n",
       "1  trips_sortedForwardIndex            316                         0   \n",
       "\n",
       "  numEntriesScannedPostFilter totalDocs timeUsedMs  \\\n",
       "0                        6004    309911         65   \n",
       "1                        6004    309911         51   \n",
       "\n",
       "  minConsumingFreshnessTimeMs exceptions  \n",
       "0               1618160041688         []  \n",
       "1               1618160039711         []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "executeSQLStatement(\"select * from XX_TABLE WHERE start_location=XX_STARTLOCATION LIMIT 10000\", [['trips_default_index', 'Default Index (Dictionary-encoded forward index with bit compression) for each column'],['trips_sortedForwardIndex', 'Sorted forward index with run-length encoding on start location']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-princess",
   "metadata": {},
   "source": [
    "The sorted forward index on column `start_location` of table `trips_sortedForwardIndex` benefits from data locality. Because of this, `numEntriesScannedInFilter` is less than for the column with default index.\n",
    "Thus, query executions can be faster when using the sorted forward index on column `start_location`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-receipt",
   "metadata": {},
   "source": [
    "#### Default Index (Dictionary-encoded forward index with bit compression) vs Inverted index (Bitmap + Sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "pleased-protocol",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top two result records of: select driver_name, rider_name from trips_default_index WHERE start_location='Emden' LIMIT 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>driver_name</th>\n",
       "      <th>rider_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michael Weston</td>\n",
       "      <td>Jeremiah Santana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Courtney Gonzalez</td>\n",
       "      <td>Patricia Stone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         driver_name        rider_name\n",
       "0     Michael Weston  Jeremiah Santana\n",
       "1  Courtney Gonzalez    Patricia Stone"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indextype</th>\n",
       "      <th>table</th>\n",
       "      <th>numDocsScanned</th>\n",
       "      <th>numEntriesScannedInFilter</th>\n",
       "      <th>numEntriesScannedPostFilter</th>\n",
       "      <th>totalDocs</th>\n",
       "      <th>timeUsedMs</th>\n",
       "      <th>minConsumingFreshnessTimeMs</th>\n",
       "      <th>exceptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default Index (Dictionary-encoded forward index with bit compression) for each column</td>\n",
       "      <td>trips_default_index</td>\n",
       "      <td>316</td>\n",
       "      <td>309911</td>\n",
       "      <td>632</td>\n",
       "      <td>309911</td>\n",
       "      <td>66</td>\n",
       "      <td>1618160041688</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bitmap inverted index on start_location</td>\n",
       "      <td>trips_bitmapInvertedIndex_startLocation</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>309911</td>\n",
       "      <td>22</td>\n",
       "      <td>1618160041841</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sorted inverted index on start_location</td>\n",
       "      <td>trips_sortedInvertedIndex_startLocation</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>309911</td>\n",
       "      <td>13</td>\n",
       "      <td>1618160040531</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               indextype  \\\n",
       "0  Default Index (Dictionary-encoded forward index with bit compression) for each column   \n",
       "1                                                Bitmap inverted index on start_location   \n",
       "2                                                Sorted inverted index on start_location   \n",
       "\n",
       "                                     table numDocsScanned  \\\n",
       "0                      trips_default_index            316   \n",
       "1  trips_bitmapInvertedIndex_startLocation            316   \n",
       "2  trips_sortedInvertedIndex_startLocation            316   \n",
       "\n",
       "  numEntriesScannedInFilter numEntriesScannedPostFilter totalDocs timeUsedMs  \\\n",
       "0                    309911                         632    309911         66   \n",
       "1                         0                         632    309911         22   \n",
       "2                         0                         632    309911         13   \n",
       "\n",
       "  minConsumingFreshnessTimeMs exceptions  \n",
       "0               1618160041688         []  \n",
       "1               1618160041841         []  \n",
       "2               1618160040531         []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "executeSQLStatement(\"select driver_name, rider_name from XX_TABLE WHERE start_location=XX_STARTLOCATION LIMIT 10000\", [['trips_default_index', 'Default Index (Dictionary-encoded forward index with bit compression) for each column'],['trips_bitmapInvertedIndex_startLocation', 'Bitmap inverted index on start_location'],['trips_sortedInvertedIndex_startLocation','Sorted inverted index on start_location']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-director",
   "metadata": {},
   "source": [
    "As we can see, an inverted index can improve the query performance. In this case, no entries have to be scanned in the filtering phase and the query execution time is faster compared to using the dictionary encoded index.\n",
    "By using the sorted inverted index, the performance can benefit from data locality. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-catch",
   "metadata": {},
   "source": [
    "#### Text Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-nerve",
   "metadata": {},
   "source": [
    "A query searching selecting drivers by first name can only be executed successfully on table `trips_textIndex`, as it has a text index defined on column `driver_name`. The same query execution on other tables will fail, the metrics table only displays the executions without an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "returning-aquarium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top two result records of: select * from trips_textIndex WHERE TEXT_MATCH ('driver_name','Michael') LIMIT 10000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>driver_name</th>\n",
       "      <th>driver_rating</th>\n",
       "      <th>end_location</th>\n",
       "      <th>end_location_state</th>\n",
       "      <th>end_zip_code</th>\n",
       "      <th>license_plate</th>\n",
       "      <th>payment_amount</th>\n",
       "      <th>payment_tip_amount</th>\n",
       "      <th>request_time_millis</th>\n",
       "      <th>rider_is_premium</th>\n",
       "      <th>rider_name</th>\n",
       "      <th>rider_rating</th>\n",
       "      <th>start_location</th>\n",
       "      <th>start_location_state</th>\n",
       "      <th>start_zip_code</th>\n",
       "      <th>trip_end_time_millis</th>\n",
       "      <th>trip_start_time_millis</th>\n",
       "      <th>trip_wait_time_millis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Michael Waldren</td>\n",
       "      <td>3</td>\n",
       "      <td>Niederstotzingen</td>\n",
       "      <td>Baden-W√ºrttemberg</td>\n",
       "      <td>89168</td>\n",
       "      <td>VS-GN-23</td>\n",
       "      <td>598.32</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1618359470089</td>\n",
       "      <td>0</td>\n",
       "      <td>Rhonda Lopez</td>\n",
       "      <td>2</td>\n",
       "      <td>Frankfurt am Main</td>\n",
       "      <td>Hessen</td>\n",
       "      <td>60594</td>\n",
       "      <td>1618396816222</td>\n",
       "      <td>1618361201936</td>\n",
       "      <td>1731847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Michael Jankowski</td>\n",
       "      <td>4</td>\n",
       "      <td>Hartenstein Zschocken</td>\n",
       "      <td>Sachsen</td>\n",
       "      <td>08118</td>\n",
       "      <td>AW-NK-98</td>\n",
       "      <td>186.39</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1618359495055</td>\n",
       "      <td>1</td>\n",
       "      <td>Clyde Bingham</td>\n",
       "      <td>1</td>\n",
       "      <td>Biesendahlshof</td>\n",
       "      <td>Brandenburg</td>\n",
       "      <td>16306</td>\n",
       "      <td>1618371437097</td>\n",
       "      <td>1618360823304</td>\n",
       "      <td>1328249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count        driver_name  driver_rating           end_location  \\\n",
       "0      1    Michael Waldren              3       Niederstotzingen   \n",
       "1      1  Michael Jankowski              4  Hartenstein Zschocken   \n",
       "\n",
       "  end_location_state end_zip_code license_plate  payment_amount  \\\n",
       "0  Baden-W√ºrttemberg        89168      VS-GN-23          598.32   \n",
       "1            Sachsen        08118      AW-NK-98          186.39   \n",
       "\n",
       "   payment_tip_amount  request_time_millis  rider_is_premium     rider_name  \\\n",
       "0                28.0        1618359470089                 0   Rhonda Lopez   \n",
       "1                10.0        1618359495055                 1  Clyde Bingham   \n",
       "\n",
       "   rider_rating     start_location start_location_state start_zip_code  \\\n",
       "0             2  Frankfurt am Main               Hessen          60594   \n",
       "1             1     Biesendahlshof          Brandenburg          16306   \n",
       "\n",
       "   trip_end_time_millis  trip_start_time_millis  trip_wait_time_millis  \n",
       "0         1618396816222           1618361201936                1731847  \n",
       "1         1618371437097           1618360823304                1328249  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indextype</th>\n",
       "      <th>table</th>\n",
       "      <th>numDocsScanned</th>\n",
       "      <th>numEntriesScannedInFilter</th>\n",
       "      <th>numEntriesScannedPostFilter</th>\n",
       "      <th>totalDocs</th>\n",
       "      <th>timeUsedMs</th>\n",
       "      <th>minConsumingFreshnessTimeMs</th>\n",
       "      <th>exceptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text Index</td>\n",
       "      <td>trips_textIndex</td>\n",
       "      <td>4742</td>\n",
       "      <td>0</td>\n",
       "      <td>90098</td>\n",
       "      <td>309911</td>\n",
       "      <td>165</td>\n",
       "      <td>1618160050199</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    indextype            table numDocsScanned numEntriesScannedInFilter  \\\n",
       "0  Text Index  trips_textIndex           4742                         0   \n",
       "\n",
       "  numEntriesScannedPostFilter totalDocs timeUsedMs  \\\n",
       "0                       90098    309911        165   \n",
       "\n",
       "  minConsumingFreshnessTimeMs exceptions  \n",
       "0               1618160050199         []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "executeSQLStatement(\"select * from XX_TABLE WHERE TEXT_MATCH ('driver_name',XX_DRIVERNAME) LIMIT 10000\", [['trips_textIndex','Text Index']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-discovery",
   "metadata": {},
   "source": [
    "#### Star-Tree Index\n",
    "\n",
    "The Start-Tree index utilizes pre-aggregation of results and is built on multiple columns. This index can improve the performance for specific queries, because the number of values to be processed is reduced by the pre-aggregation. Although usage of a Star-Tree index has the advantage of decreased query runtime, the table size on disk is significantly increased.\n",
    "For table `trips_starTreeIndex`, a Star-Tree index is built on the dimensions `rider_is_premium`, `start_location_state` and `end_location`. The sum of `payment_amount` is pre-aggregated and materialized based on the configured dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "durable-maldives",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top two result records of: SELECT SUM(payment_amount) FROM trips_default_index\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum(payment_amount)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.180779e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum(payment_amount)\n",
       "0         2.180779e+08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indextype</th>\n",
       "      <th>table</th>\n",
       "      <th>numDocsScanned</th>\n",
       "      <th>numEntriesScannedInFilter</th>\n",
       "      <th>numEntriesScannedPostFilter</th>\n",
       "      <th>totalDocs</th>\n",
       "      <th>timeUsedMs</th>\n",
       "      <th>minConsumingFreshnessTimeMs</th>\n",
       "      <th>exceptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default Index (Dictionary-encoded forward index with bit compression) for each column</td>\n",
       "      <td>trips_default_index</td>\n",
       "      <td>309911</td>\n",
       "      <td>0</td>\n",
       "      <td>309911</td>\n",
       "      <td>309911</td>\n",
       "      <td>40</td>\n",
       "      <td>1618160041688</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Start Tree</td>\n",
       "      <td>trips_starTreeIndex</td>\n",
       "      <td>9926</td>\n",
       "      <td>0</td>\n",
       "      <td>9926</td>\n",
       "      <td>309911</td>\n",
       "      <td>21</td>\n",
       "      <td>1618160046884</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               indextype  \\\n",
       "0  Default Index (Dictionary-encoded forward index with bit compression) for each column   \n",
       "1                                                                             Start Tree   \n",
       "\n",
       "                 table numDocsScanned numEntriesScannedInFilter  \\\n",
       "0  trips_default_index         309911                         0   \n",
       "1  trips_starTreeIndex           9926                         0   \n",
       "\n",
       "  numEntriesScannedPostFilter totalDocs timeUsedMs  \\\n",
       "0                      309911    309911         40   \n",
       "1                        9926    309911         21   \n",
       "\n",
       "  minConsumingFreshnessTimeMs exceptions  \n",
       "0               1618160041688         []  \n",
       "1               1618160046884         []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "executeSQLStatement(\"SELECT SUM(payment_amount) FROM XX_TABLE\",[[\"trips_default_index\",\"Default Index (Dictionary-encoded forward index with bit compression) for each column\"],[\"trips_starTreeIndex\", \"Start Tree\"]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-logan",
   "metadata": {},
   "source": [
    "When selecting the Star-Node without grouping by any dimension, Pinot doesn't need to access all documents. Instead, only the Star-Node of each segment is required. The reason, why `numDocsScanned` is not equal to the number of segments is, that there is always one segment that isn't completed yet. Pinot accesses each record of the consuming segment (status `IN_PROGRESS`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "extraordinary-auditor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table with the Star Tree Index consists of 16 segments\n"
     ]
    }
   ],
   "source": [
    "print(\"The table with the Star Tree Index consists of \" + str(len(requests.get('http://pinot-controller.pinot:9000/segments/trips_starTreeIndex').json()[0]['REALTIME'])) + \" segments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-accessory",
   "metadata": {},
   "source": [
    "Filtering on the dimension `rider_is_premium`, which builds the first node of the Star-Tree index, halves the number of `numDocsScanned`. This is because `rider_is_premiumn` is assigned randomly in our data generation, so there is a fifty percent chance that a rider is not premium and less documents of the consuming segment need to be scanned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "diverse-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top two result records of: SELECT SUM(payment_amount) FROM trips_default_index WHERE rider_is_premium = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum(payment_amount)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.090266e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum(payment_amount)\n",
       "0         1.090266e+08"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indextype</th>\n",
       "      <th>table</th>\n",
       "      <th>numDocsScanned</th>\n",
       "      <th>numEntriesScannedInFilter</th>\n",
       "      <th>numEntriesScannedPostFilter</th>\n",
       "      <th>totalDocs</th>\n",
       "      <th>timeUsedMs</th>\n",
       "      <th>minConsumingFreshnessTimeMs</th>\n",
       "      <th>exceptions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Default Index (Dictionary-encoded forward index with bit compression) for each column</td>\n",
       "      <td>trips_default_index</td>\n",
       "      <td>154900</td>\n",
       "      <td>309911</td>\n",
       "      <td>154900</td>\n",
       "      <td>309911</td>\n",
       "      <td>35</td>\n",
       "      <td>1618160041688</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Start Tree</td>\n",
       "      <td>trips_starTreeIndex</td>\n",
       "      <td>4950</td>\n",
       "      <td>9911</td>\n",
       "      <td>4950</td>\n",
       "      <td>309911</td>\n",
       "      <td>17</td>\n",
       "      <td>1618160046884</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                               indextype  \\\n",
       "0  Default Index (Dictionary-encoded forward index with bit compression) for each column   \n",
       "1                                                                             Start Tree   \n",
       "\n",
       "                 table numDocsScanned numEntriesScannedInFilter  \\\n",
       "0  trips_default_index         154900                    309911   \n",
       "1  trips_starTreeIndex           4950                      9911   \n",
       "\n",
       "  numEntriesScannedPostFilter totalDocs timeUsedMs  \\\n",
       "0                      154900    309911         35   \n",
       "1                        4950    309911         17   \n",
       "\n",
       "  minConsumingFreshnessTimeMs exceptions  \n",
       "0               1618160041688         []  \n",
       "1               1618160046884         []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "executeSQLStatement(\"SELECT SUM(payment_amount) FROM XX_TABLE WHERE rider_is_premium = 0\",[[\"trips_default_index\",\"Default Index (Dictionary-encoded forward index with bit compression) for each column\"],[\"trips_starTreeIndex\", \"Start Tree\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-mathematics",
   "metadata": {},
   "source": [
    "##### Trace Details For Star-Tree Index\n",
    "\n",
    "The trace details of the query execution display how much time was spent for which operator execution. We extract the operator details of the following query. The query executed on `trips_default_index` requires a lot of Aggregation Operators, as no data is pre-aggregated like it is the case for the table `trips_starTreeIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "composite-camcorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: SELECT SUM(payment_amount) FROM trips_starTreeIndex WHERE rider_is_premium = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operator</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AggregationOnlyCombineOperator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InstanceResponseOperator</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BitmapBasedFilterOperator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>StarTreeFilterOperator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DocIdSetOperator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ProjectionOperator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TransformOperator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AggregationOperator</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ScanBasedFilterOperator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         operator  time\n",
       "0  AggregationOnlyCombineOperator     3\n",
       "1        InstanceResponseOperator     4\n",
       "2       BitmapBasedFilterOperator     0\n",
       "3          StarTreeFilterOperator     0\n",
       "4                DocIdSetOperator     1\n",
       "5              ProjectionOperator     1\n",
       "6               TransformOperator     1\n",
       "7             AggregationOperator     3\n",
       "8         ScanBasedFilterOperator     0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: SELECT SUM(payment_amount) FROM trips_default_index WHERE rider_is_premium = 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>operator</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AggregationOnlyCombineOperator</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InstanceResponseOperator</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ScanBasedFilterOperator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DocIdSetOperator</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ProjectionOperator</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TransformOperator</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AggregationOperator</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         operator  time\n",
       "0  AggregationOnlyCombineOperator    25\n",
       "1        InstanceResponseOperator    25\n",
       "2         ScanBasedFilterOperator     0\n",
       "3                DocIdSetOperator    11\n",
       "4              ProjectionOperator    12\n",
       "5               TransformOperator    12\n",
       "6             AggregationOperator    24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_trace_per_operator_from_result(result):\n",
    "    trace_data_per_operator = {}\n",
    "    for server, server_trace_json in result[\"traceInfo\"].items():\n",
    "        server_trace = json.loads(server_trace_json)\n",
    "        for trace_dict in server_trace:\n",
    "            for segment, segment_trace in trace_dict.items():\n",
    "                for segment_trace_element in segment_trace:\n",
    "                    for operator, operator_time in segment_trace_element.items():\n",
    "                        try:\n",
    "                            trace_data_per_operator[operator] += operator_time\n",
    "                        except KeyError:\n",
    "                            trace_data_per_operator[operator] = operator_time\n",
    "    \n",
    "    trace_data_array = []\n",
    "    for operator, operator_time in trace_data_per_operator.items():\n",
    "        trace_data_array.append({\"operator\": operator.replace(\" Time\", \"\"), \"time\": operator_time})\n",
    "    return pd.DataFrame(trace_data_array)\n",
    "\n",
    "display(extract_trace_per_operator_from_result(query_sql(\"SELECT SUM(payment_amount) FROM trips_starTreeIndex WHERE rider_is_premium = 0\")))\n",
    "\n",
    "display(extract_trace_per_operator_from_result(query_sql(\"SELECT SUM(payment_amount) FROM trips_default_index WHERE rider_is_premium = 0\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-lightning",
   "metadata": {},
   "source": [
    "### Indexes - Comparison with other database technologies\n",
    "\n",
    "Two categories of the indexing options demonstrated above, that can also be found in traditional databases, are Forward Indexes and Inverted Indexes.\n",
    "Forward Indexes are frequently used in traditional database technologies as well to improve storage efficiency.\n",
    "Search Engines most often rely on a inverted index, like for example EleasticSearch.\n",
    "We saw, that there is a special index to do a fulltext search for records containing a specific string.\n",
    "\n",
    "We also demonstrated two other indexing techniques, that are typically not offered by traditional database systems: raw value forward index and Star-Tree index.\n",
    "The raw value forward index doesn't include dictionaries - when aggregating a large number of values, it can take advantage of data locality for scanning.\n",
    "\n",
    "The Star-Tree Index is an important and special concept for Pinot, because it is utilizes pre-aggregation for group-by queries to achieve low query latencies. It is specifically designed for the analytical use cases which Pinot was built for and makes it a a key differenciator of Pinot.\n",
    "E.g. Star-Tree Indexes can bring great benefits, if there is the requirement to return data e.g. per user level - like it is the case for the \"Who viewed my Profile\" application at LinkedIn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-crack",
   "metadata": {},
   "source": [
    "# Closing Remarks\n",
    "\n",
    "Compared to most other common databases, setting up Pinot is more complicated as multiple different components are part of a Pinot cluster.\n",
    "The several different components ensure the flexible scale up of the cluster and the high availability, as the system would continue to serve queries also if in the event of one node going down. This is a big advantage, but the different components also add more operational complexity to the whole landscape.\n",
    "\n",
    "We experienced the advantages of Pinot, e.g. the possibility to easily stream a high number of data records from a Kafka topic into a table with high throughput. Of course, our experience doesn‚Äôt represent a use case like how LinkedIn is using Pinot, as we are producing data for the Kafka stream only once - there is no continuous data stream to the Pinot tables. For demonstration purposes, we wait for the data stream to finish loading to ensure, that there are enough data records for our analysis. In a real scenario, you would operate and execute queries while data is ingested.\n",
    "\n",
    "To summarize, Pinot is not a general-purpose database like for example PostgreSQL, but is rather highly-specialized database technology. It is definitely more complex to operate and understand, but offers great values for the specific use cases it was built for: near-realtime analytics of huge datasets. Especially the segmentation of tables, hybrid table queries and specialized indexing options contribute to Pinot's extreme scalability, flexibility and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-crest",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [1] The Apache Software Foundation, \"Apache Pinot Docs\", 2021. [Online]. Available at: https://docs.pinot.apache.org/. [Accessed: 11-Apr-2021]\n",
    "- [2] Rogers, Ryan, et al., \"LinkedIn's Audience Engagements API: A Privacy Preserving Data Analytics System at Scale\", 2020. ArXiv, abs/2002.05839.\n",
    "- [3] Im, J.-F., et al., \"Pinot: Realtime OLAP for 530 Million Users.\", 2018. Proceedings\n",
    "- [4] Jiang, X., \"Star-tree index: Powering fast aggregations on Pinot\", 2019. [Online]. Available at: https://engineering.linkedin.com/blog/2019/06/star-tree-index--powering-fast-aggregations-on-pinot. [Accessed: 30-Mar-2021]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
