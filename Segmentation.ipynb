{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fewer-petroleum",
   "metadata": {},
   "source": [
    "## Segmentation in Pinot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-sheffield",
   "metadata": {},
   "source": [
    "Table contents in Pinot are expected to grow infinitely and thus need to be distributed across multiple nodes. The dataset is split into segments, which are comparable to shards/partitions in classical RDBMS. Segmentation is done in a time-based fashion, meaning that rows in a given segment will be timewisely close to each other.\n",
    "Segments store all columns of a table and organize data in columnar orientation for high encoding efficiency and optional pre-aggregation of metrics. In addition to values, segments store indices and other lookup-related data structures like dictionaries. By default values are stored using dictionary encoding, meaning that values are represented as dictionary IDs that reference a corresponding dictionary entry. This way, values can be stored with the minimum number of bits required, which depends on the cardinality of the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import fileinput\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "from kafka import KafkaConsumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpers\n",
    "def server_name_from_instance(instance):\n",
    "    return re.search('pinot-server-[0-9]+', instance).group()\n",
    "\n",
    "def query_sql(query):\n",
    "    print(\"query: \" + query)\n",
    "    return requests.get('http://pinot-broker.pinot:8099/query/sql', params={\n",
    "        \"sql\" : query,\n",
    "        \"trace\": \"true\"\n",
    "    }).json()\n",
    "\n",
    "def query_result_to_dataframe(result):\n",
    "    return pd.DataFrame(columns=result['resultTable']['dataSchema']['columnNames'], data=result['resultTable']['rows'])\n",
    "\n",
    "def extract_query_statistics_from_result(result):\n",
    "    query_statistics_fields = [\"numServersQueried\",\"numServersResponded\",\"numSegmentsQueried\",\"numSegmentsProcessed\",\"numSegmentsMatched\",\"numConsumingSegmentsQueried\",\"numDocsScanned\",\"numEntriesScannedInFilter\",\"numEntriesScannedPostFilter\",\"numGroupsLimitReached\",\"totalDocs\",\"timeUsedMs\"]\n",
    "    return { key: result[key] for key in query_statistics_fields }\n",
    "\n",
    "def extract_query_statistics_from_result_dataframe(result):\n",
    "    return pd.DataFrame({\"value\": extract_query_statistics_from_result(result)})\n",
    "\n",
    "ordinal_pattern = re.compile(r'__[0-9]+__([0-9]+)__')\n",
    "def sort_by_ascending_ordinal(segments):\n",
    "    segments.sort(key=lambda L: (int(ordinal_pattern.search(L).group(1)), L))\n",
    "\n",
    "def segment_metadata_for_table(table):\n",
    "    segments = requests.get(f'http://pinot-controller.pinot:9000/segments/{table}').json()\n",
    "    \n",
    "    segment_metadata = {}\n",
    "    for segments_item in segments:\n",
    "        for table_type, type_segments in segments_item.items():\n",
    "            for segment in type_segments:\n",
    "                segment_type_name = f\"{segment}_{table_type}\"\n",
    "                segment_metadata[segment_type_name] = requests.get(f'http://pinot-controller.pinot:9000/segments/{table}/{segment}/metadata').json()\n",
    "    \n",
    "    return segment_metadata\n",
    "\n",
    "def segment_metadata_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\"):\n",
    "    segments_of_type = []\n",
    "    for segment in segment_metadata.keys():\n",
    "        if segment.endswith(\"_\" + table_type):\n",
    "            segments_of_type.append(segment)\n",
    "    \n",
    "    sort_by_ascending_ordinal(segments_of_type)\n",
    "    return segment_metadata[segments_of_type[n]]\n",
    "\n",
    "\n",
    "def start_time_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\"):\n",
    "    return segment_metadata_of_nth_segment(segment_metadata, n, table_type)[\"segment.start.time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer = KafkaConsumer(group_id='test', bootstrap_servers=['pinot-kafka.pinot:9092'])\n",
    "# consumer.topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requests.get('http://pinot-controller.pinot:9000/schemas/trips').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-spirituality",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_config = {\n",
    "  \"tableName\": \"\",\n",
    "  \"tableType\": \"REALTIME\",\n",
    "  \"segmentsConfig\": {\n",
    "    \"timeColumnName\": \"trip_start_time_millis\",\n",
    "    \"timeType\": \"MILLISECONDS\",\n",
    "    \"retentionTimeUnit\": \"DAYS\",\n",
    "    \"retentionTimeValue\": \"60\",\n",
    "    \"schemaName\": \"trips\",\n",
    "    \"replication\": \"1\",\n",
    "    \"replicasPerPartition\": \"1\"\n",
    "  },\n",
    "  \"tenants\": {},\n",
    "  \"tableIndexConfig\": {\n",
    "    \"loadMode\": \"MMAP\",\n",
    "    \"invertedIndexColumns\": [\n",
    "        \"rider_name\",\n",
    "        \"driver_name\",\n",
    "        \"start_location\",\n",
    "        \"end_location\"\n",
    "    ],\n",
    "    \"streamConfigs\": {\n",
    "      \"streamType\": \"kafka\",\n",
    "      \"stream.kafka.consumer.type\": \"simple\",\n",
    "      \"stream.kafka.topic.name\": \"trips\",\n",
    "      \"stream.kafka.decoder.class.name\": \"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\",\n",
    "      \"stream.kafka.consumer.factory.class.name\": \"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\",\n",
    "      \"stream.kafka.zk.broker.url\": \"pinot-kafka-zookeeper:2181\",\n",
    "      \"stream.kafka.broker.list\": \"pinot-kafka:9092\",\n",
    "      \"realtime.segment.flush.threshold.time\": \"12h\",\n",
    "      \"realtime.segment.flush.threshold.size\": \"80000\",\n",
    "      \"stream.kafka.consumer.prop.auto.offset.reset\": \"smallest\"\n",
    "    }\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"customConfigs\": {}\n",
    "  }\n",
    "}\n",
    "\n",
    "table_config[\"tableName\"] = \"trips_segmentation_1\"\n",
    "print(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())\n",
    "\n",
    "table_config[\"tableName\"] = \"trips_segmentation_2\"\n",
    "table_config[\"segmentsConfig\"][\"replication\"] = \"3\"\n",
    "table_config[\"segmentsConfig\"][\"replicasPerPartition\"] = \"3\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.size\"] = \"50000\"\n",
    "print(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-filename",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.get('http://pinot-controller.pinot:9000/segments/trips_segmentation_1').json()\n",
    "# segments_1 = response[0]['REALTIME']\n",
    "# sort_by_ascending_ordinal(segments_1)\n",
    "# pd.DataFrame(segments_1, columns=['trips_segmentation_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-wheat",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# response = requests.get('http://pinot-controller.pinot:9000/segments/trips_segmentation_2').json()\n",
    "# segments_2 = response[0]['REALTIME']\n",
    "# sort_by_ascending_ordinal(segments_2)\n",
    "# pd.DataFrame(segments_2, columns=['trips_segmentation_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_metadata_1 = segment_metadata_for_table(\"trips_segmentation_1\")\n",
    "pd.DataFrame(segment_metadata_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_metadata_2 = segment_metadata_for_table(\"trips_segmentation_2\")\n",
    "pd.DataFrame(segment_metadata_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-syntax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from first 2 segments\n",
    "query_for_trips_segmentation_1 = f\"select driver_name, sum(count) as trips_count from trips_segmentation_1 where trip_start_time_millis < {start_time_of_nth_segment(segment_metadata_1, 1)} group by driver_name order by trips_count desc limit 5\"\n",
    "\n",
    "query_result = query_sql(query_for_trips_segmentation_1)\n",
    "display(query_result_to_dataframe(query_result))\n",
    "display(extract_query_statistics_from_result_dataframe(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from first 3 segments\n",
    "query_for_trips_segmentation_2 = f\"select driver_name, sum(count) as trips_count from trips_segmentation_2 where trip_start_time_millis < {start_time_of_nth_segment(segment_metadata_2, 2)} group by driver_name order by trips_count desc limit 5\"\n",
    "\n",
    "query_result = query_sql(query_for_trips_segmentation_2)\n",
    "display(query_result_to_dataframe(query_result))\n",
    "display(extract_query_statistics_from_result_dataframe(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-disability",
   "metadata": {},
   "source": [
    "## Query Routing / Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-subsection",
   "metadata": {},
   "source": [
    "Brokers are responsible for maintaining routing tables, which contain mappings between segments of a table and servers where they are hosted on. This allows brokers to efficiently scatter received queries across servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpers\n",
    "def routing_table_for_query(query):\n",
    "    print(\"query: \" + query)\n",
    "    return requests.get('http://pinot-broker.pinot:8099/debug/routingTable/sql', params={\n",
    "        \"query\" : query\n",
    "    }).json()\n",
    "\n",
    "def routing_table_for_table(table):\n",
    "    return requests.get(f'http://pinot-broker.pinot:8099/debug/routingTable/{table}').json()\n",
    "\n",
    "def external_view_for_table(table):\n",
    "    return requests.get(f'http://pinot-controller.pinot:9000/tables/{table}/externalview').json()\n",
    "\n",
    "def routing_table_for_query_dataframe(query):\n",
    "    rt = routing_table_for_query(query)\n",
    "    rt_data = {}\n",
    "\n",
    "    for server, server_segments in rt.items():\n",
    "        server_name = server_name_from_instance(server)\n",
    "        for s in server_segments:\n",
    "            rt_data[s] = server_name\n",
    "\n",
    "    rt_data_list = []\n",
    "    for segment, server in rt_data.items():\n",
    "        rt_data_list.append({\"segment\": segment, \"server\": server})\n",
    "\n",
    "    rt_data_list.sort(key=lambda L: (int(ordinal_pattern.search(L[\"segment\"]).group(1)), L))\n",
    "    return pd.DataFrame(rt_data_list)\n",
    "\n",
    "def routing_table_for_table_dataframe(table):\n",
    "    rt = routing_table_for_table(table)\n",
    "    rt_data = {}\n",
    "\n",
    "    for table_name_type, table_rt in rt.items():\n",
    "        table_type = re.search('REALTIME|OFFLINE', table_name_type).group()\n",
    "        for server, server_segments in table_rt.items():\n",
    "            server_name = server_name_from_instance(server)\n",
    "            for s in server_segments:\n",
    "                try:\n",
    "                    rt_data[s][table_type] = server_name\n",
    "                except KeyError:\n",
    "                    rt_data[s] = {table_type: server_name}\n",
    "\n",
    "    rt_data_list = []\n",
    "    for segment, type_server in rt_data.items():\n",
    "        segment_data = {\"segment\": segment}\n",
    "        for table_type, server in type_server.items():\n",
    "            segment_data[table_type] = server\n",
    "        rt_data_list.append(segment_data)\n",
    "\n",
    "    rt_data_list.sort(key=lambda L: (int(ordinal_pattern.search(L[\"segment\"]).group(1)), L))\n",
    "    return pd.DataFrame(rt_data_list)\n",
    "\n",
    "def external_view_for_table_dataframe(table):\n",
    "    ev = external_view_for_table(table)\n",
    "    ev_data = {}\n",
    "\n",
    "    for table_type, ev_per_type in ev.items():\n",
    "        if ev_per_type == None:\n",
    "            continue\n",
    "        \n",
    "        for segment, segment_servers in ev_per_type.items():\n",
    "            if not segment in ev_data:\n",
    "                ev_data[segment] = {}\n",
    "            for server, state in segment_servers.items():\n",
    "                server_name = server_name_from_instance(server)\n",
    "                try:\n",
    "                    ev_data[segment][table_type].append(server_name)\n",
    "                except KeyError:\n",
    "                    ev_data[segment][table_type] = [server_name]\n",
    "\n",
    "    return pd.DataFrame(ev_data).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_view_for_table_dataframe(\"trips_segmentation_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_view_for_table_dataframe(\"trips_segmentation_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_table_for_query_dataframe(query_for_trips_segmentation_1.replace(\"trips_segmentation_1\", \"trips_segmentation_1_REALTIME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_table_for_query_dataframe(query_for_trips_segmentation_2.replace(\"trips_segmentation_2\", \"trips_segmentation_2_REALTIME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-procurement",
   "metadata": {},
   "source": [
    "# Batch ingestion and Hybrid Tables\n",
    "\n",
    "Segments are transferred as tar archives and can be downloaded from the controller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_config = {\n",
    "  \"tableName\": \"trips_hybrid\",\n",
    "  \"tableType\": \"OFFLINE\",\n",
    "  \"segmentsConfig\": {\n",
    "    \"timeColumnName\": \"trip_start_time_millis\",\n",
    "    \"timeType\": \"MILLISECONDS\",\n",
    "    \"retentionTimeUnit\": \"DAYS\",\n",
    "    \"retentionTimeValue\": \"60\",\n",
    "    \"schemaName\": \"trips\",\n",
    "    \"replication\": \"1\"\n",
    "  },\n",
    "  \"tenants\": {},\n",
    "  \"tableIndexConfig\": {\n",
    "    \"loadMode\": \"MMAP\",\n",
    "    \"invertedIndexColumns\": [\n",
    "        \"rider_name\",\n",
    "        \"driver_name\",\n",
    "        \"start_location\",\n",
    "        \"end_location\"\n",
    "    ]\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"customConfigs\": {}\n",
    "  }\n",
    "}\n",
    "\n",
    "# create offline table\n",
    "print(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())\n",
    "\n",
    "# create realtime table\n",
    "table_config[\"tableType\"] = \"REALTIME\"\n",
    "table_config[\"segmentsConfig\"][\"replicasPerPartition\"] = \"1\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"] = {\n",
    "  \"streamType\": \"kafka\",\n",
    "  \"stream.kafka.consumer.type\": \"simple\",\n",
    "  \"stream.kafka.topic.name\": \"trips\",\n",
    "  \"stream.kafka.decoder.class.name\": \"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\",\n",
    "  \"stream.kafka.consumer.factory.class.name\": \"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\",\n",
    "  \"stream.kafka.zk.broker.url\": \"pinot-kafka-zookeeper:2181\",\n",
    "  \"stream.kafka.broker.list\": \"pinot-kafka:9092\",\n",
    "  \"realtime.segment.flush.threshold.time\": \"12h\",\n",
    "  \"realtime.segment.flush.threshold.size\": \"50000\",\n",
    "  \"stream.kafka.consumer.prop.auto.offset.reset\": \"smallest\"\n",
    "}\n",
    "print(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_view_for_table_dataframe(\"trips_hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-favor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers for transforming realtime segments to offline segment\n",
    "tmp_hybrid_basedir = \"/tmp/trips_hybrid\"\n",
    "try:\n",
    "    os.mkdir(tmp_hybrid_basedir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "def path_for_realtime_tar(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}.tar.gz\"\n",
    "\n",
    "def path_for_offline_dir(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}_offline\"\n",
    "\n",
    "def path_for_offline_tar(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}_offline.tar.gz\"\n",
    "\n",
    "def download_segment(segment_metadata):\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    download_url = segment_metadata[\"segment.realtime.download.url\"]\n",
    "    segment_realtime_tar = path_for_realtime_tar(segment_name)\n",
    "\n",
    "    # cleanup old downloads\n",
    "    try:\n",
    "        os.remove(segment_realtime_tar)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    # download realtime segment tar\n",
    "    response = requests.get(download_url, stream=True)\n",
    "    with open(segment_realtime_tar, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response.raw, out_file)\n",
    "    del response\n",
    "    \n",
    "    print(f\"segment {segment_name} downloaded from {download_url} to {segment_realtime_tar}\")\n",
    "    return segment_realtime_tar\n",
    "\n",
    "def untar_segment(segment_metadata):\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_basedir = path_for_offline_dir(segment_name)\n",
    "    segment_realtime_tar = path_for_realtime_tar(segment_name)\n",
    "\n",
    "    # cleanup old artifacts if any\n",
    "    shutil.rmtree(segment_offline_basedir, ignore_errors=True)\n",
    "\n",
    "    # extract downloaded segment tar\n",
    "    with tarfile.open(segment_realtime_tar, 'r:gz') as tar:\n",
    "        tar.extractall(path=segment_offline_basedir)\n",
    "\n",
    "    print(f\"segment {segment_name} untarred to {segment_offline_basedir}\")\n",
    "    return segment_offline_basedir\n",
    "\n",
    "def transform_segment(segment_metadata):\n",
    "    realtime_table_name = segment_metadata[\"segment.table.name\"]\n",
    "    offline_table_name = realtime_table_name.replace(\"REALTIME\", \"OFFLINE\")\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_basedir = path_for_offline_dir(segment_name)\n",
    "    \n",
    "    # modify metadata.properties of segment\n",
    "    segment_offline_dir = segment_offline_basedir + \"/\" + segment_name\n",
    "    metadata_file = segment_offline_dir + \"/v3/metadata.properties\"\n",
    "    metadata_contents = None\n",
    "    with open(metadata_file, 'r') as file:\n",
    "      metadata_contents = file.read()\n",
    "    \n",
    "    metadata_contents = metadata_contents.replace(realtime_table_name, offline_table_name)\n",
    "    \n",
    "    with open(metadata_file, 'w') as file:\n",
    "      file.write(metadata_contents)\n",
    "    del metadata_contents\n",
    "\n",
    "    # create new offline segment tar\n",
    "    segment_offline_tar = path_for_offline_tar(segment_name)\n",
    "    with tarfile.open(segment_offline_tar, 'w:gz') as tar:\n",
    "        tar.add(segment_offline_dir, arcname=segment_name)\n",
    "\n",
    "    print(f\"segment {segment_name} transformed to offline segment to {segment_offline_tar}\")\n",
    "    return segment_offline_tar\n",
    "\n",
    "def upload_segment_to_offline_table(segment_metadata):\n",
    "    realtime_table_name = segment_metadata[\"segment.table.name\"]\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_tar = path_for_offline_tar(segment_name)\n",
    "    table_name = realtime_table_name.replace(\"_REALTIME\", \"_OFFLINE\")\n",
    "    \n",
    "    # POST segment as multipart/form-data for key 'segment'\n",
    "    with open(segment_offline_tar, 'rb') as tar:\n",
    "        response = requests.post(f'http://pinot-controller.pinot:9000/v2/segments?table={table_name}', files={\n",
    "            'segment': tar\n",
    "        })\n",
    "        print(response)\n",
    "        print(response.json())\n",
    "\n",
    "def transform_and_upload_nth_segment_to_offline_table(segment_metadata, n):\n",
    "    nth_meta = segment_metadata_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\")\n",
    "    \n",
    "    # download, transform and upload all in one row\n",
    "    download_segment(nth_meta)\n",
    "    untar_segment(nth_meta)\n",
    "    transform_segment(nth_meta)\n",
    "    upload_segment_to_offline_table(nth_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_metadata_hybrid = segment_metadata_for_table(\"trips_hybrid\")\n",
    "\n",
    "transform_and_upload_nth_segment_to_offline_table(segment_metadata_hybrid, 0)\n",
    "transform_and_upload_nth_segment_to_offline_table(segment_metadata_hybrid, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-label",
   "metadata": {},
   "source": [
    "### Segment URI Push\n",
    "Let controller fetch segment tar from some blob store ([docs](https://docs.pinot.apache.org/basics/data-import/batch-ingestion#segment-uri-push))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = requests.post('http://pinot-controller.pinot:9000/v2/segments?table=trips_hybrid', headers={\n",
    "#     'UPLOAD_TYPE': 'URI',\n",
    "#     'DOWNLOAD_URI': download_url\n",
    "# })\n",
    "# print(response)\n",
    "# print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-specific",
   "metadata": {},
   "source": [
    "### Segment Tar Push\n",
    "Push segment tar to controller ([docs](https://docs.pinot.apache.org/basics/data-import/batch-ingestion#segment-tar-push))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload transformed segment\n",
    "# upload_segment_to_offline_table(segment_metadata_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-quantum",
   "metadata": {},
   "source": [
    "### Show external view for hybrid table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_view_for_table_dataframe(\"trips_hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segment_metadata_hybrid = segment_metadata_for_table(\"trips_hybrid\")\n",
    "# pd.DataFrame(segment_metadata_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-brass",
   "metadata": {},
   "source": [
    "### Example Query: Top 5 drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_for_hybrid = \"\"\"\n",
    "    SELECT driver_name, sum(count) as trips\n",
    "    FROM trips_hybrid\n",
    "    GROUP BY driver_name\n",
    "    HAVING trips > 1\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "\n",
    "query_result_to_dataframe(query_sql(query_for_hybrid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
