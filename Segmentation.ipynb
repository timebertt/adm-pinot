{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "loving-groove",
   "metadata": {},
   "source": [
    "# Segmentation in Pinot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-antigua",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Table contents in Pinot are expected to grow infinitely and thus need to be distributed across multiple nodes. Therefore, the tables' dataset is split into segments, which are comparable to shards/partitions in classical RDBMSs. In Pinot, segmentation is done in a time-based fashion, meaning that configured timestamps of records in a given segment will be close to each other.\n",
    "Segments store all columns of a table and organize data in columnar orientation for high encoding efficiency and optional pre-aggregation of metrics. In addition to the data itself, segments contain indices and other lookup-related data structures like dictionaries.\n",
    "\n",
    "As Pinot is not a general-purpose database (data is immutable), it cannot be used as an application's \"main datastore\". Like other OLAP stores, Pinot is supposed to run next to the application's \"main datastore\" and its data has to be imported separately (ingestion). In order to facilitate near-realtime analytical queries, for example like the ones powering LinkedIn's well-known \"Who viewed my profile\" functionality, data is typically ingested into Pinot via event streaming platforms, like Apache Kafka (stream ingestion). In contrast to classical RDBMSs, Pinot comes with built-in support for directly reading from Kafka event streams.\n",
    "However, data can also be ingested from traditional batch processing workflows, for example realized with Apache Hadoop or Apache Spark (batch ingestion).\n",
    "\n",
    "Pinot tables are either defined as realtime or offline tables. Tables of both types are broken into segments. For realtime tables, data is consumed directly from event streams by Pinot servers as-is without any additional processing. Segments are built inside Pinot and are completed once a given threshold in size or time is reached. Segments for offline tables are built outside of Pinot in batch processing jobs, that might perform additional data deduplication or similar processing, and uploaded to the Pinot controller. Both table types might be combined to form hybrid tables, that allow both realtime analytics as well as long-term data storage (covered later on)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-rocket",
   "metadata": {},
   "source": [
    "## Realtime Data Ingestion\n",
    "\n",
    "To demonstrate how segments work in Pinot, we're going to focus on realtime data ingestion first. In the following examples, we'll be using the controller's and broker's REST APIs in order to dynamically create realtime tables, retrieve segment metadata and execute SQL queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-national",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import copy\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import fileinput\n",
    "import tarfile\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpers for the upcoming examples\n",
    "def server_name_from_instance(instance):\n",
    "    return re.search('pinot-server-[0-9]+', instance).group()\n",
    "\n",
    "def query_sql(query):\n",
    "    print(\"query: \" + query)\n",
    "    return requests.get('http://pinot-broker.pinot:8099/query/sql', params={\n",
    "        \"sql\" : query,\n",
    "        \"trace\": \"true\"\n",
    "    }).json()\n",
    "\n",
    "def query_result_to_dataframe(result):\n",
    "    return pd.DataFrame(columns=result['resultTable']['dataSchema']['columnNames'], data=result['resultTable']['rows'])\n",
    "\n",
    "def extract_query_statistics_from_result(result):\n",
    "    query_statistics_fields = [\"numServersQueried\",\"numServersResponded\",\"numSegmentsQueried\",\"numSegmentsProcessed\",\"numSegmentsMatched\",\"numConsumingSegmentsQueried\",\"numDocsScanned\",\"numEntriesScannedInFilter\",\"numEntriesScannedPostFilter\",\"numGroupsLimitReached\",\"totalDocs\",\"timeUsedMs\"]\n",
    "    return { key: result[key] for key in query_statistics_fields }\n",
    "\n",
    "def extract_query_statistics_from_result_dataframe(result):\n",
    "    return pd.DataFrame({\"value\": extract_query_statistics_from_result(result)})\n",
    "\n",
    "ordinal_pattern = re.compile(r'__[0-9]+__([0-9]+)__')\n",
    "def sort_by_ascending_ordinal(segments):\n",
    "    segments.sort(key=lambda L: (int(ordinal_pattern.search(L).group(1)), L))\n",
    "\n",
    "def segment_metadata_for_table(table):\n",
    "    segments = requests.get(f'http://pinot-controller.pinot:9000/segments/{table}').json()\n",
    "    \n",
    "    segment_metadata = {}\n",
    "    for segments_item in segments:\n",
    "        for table_type, type_segments in segments_item.items():\n",
    "            for segment in type_segments:\n",
    "                segment_type_name = f\"{segment}_{table_type}\"\n",
    "                segment_metadata[segment_type_name] = requests.get(f'http://pinot-controller.pinot:9000/segments/{table}/{segment}/metadata').json()\n",
    "    \n",
    "    return segment_metadata\n",
    "\n",
    "def segment_metadata_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\"):\n",
    "    segments_of_type = []\n",
    "    for segment in segment_metadata.keys():\n",
    "        if segment.endswith(\"_\" + table_type):\n",
    "            segments_of_type.append(segment)\n",
    "    \n",
    "    sort_by_ascending_ordinal(segments_of_type)\n",
    "    return segment_metadata[segments_of_type[n]]\n",
    "\n",
    "\n",
    "def start_time_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\"):\n",
    "    return segment_metadata_of_nth_segment(segment_metadata, n, table_type)[\"segment.start.time\"]\n",
    "\n",
    "def wait_for_table_to_finish_loading(table, wait_time=15):\n",
    "    last_total_docs = -1\n",
    "    while True:\n",
    "        response = requests.post('http://pinot-broker.pinot:8099/query/sql', json={\"sql\" : f\"SELECT * FROM {table} LIMIT 1\"}).json()\n",
    "        total_docs = response[\"totalDocs\"]\n",
    "        if total_docs == last_total_docs:\n",
    "            print(f\"--Consumption of generated data for table {table} finished, (loaded {last_total_docs} docs)--\")\n",
    "            break\n",
    "        \n",
    "        last_total_docs = total_docs\n",
    "        print(f\"waiting for table {table} to finish loading (loaded {last_total_docs} docs)\")\n",
    "        time.sleep(wait_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-rings",
   "metadata": {},
   "source": [
    "At first, we will create two realtime tables. Both will be using the `trips` schema created above and read from the `trips` topic in Kafka, that was also created and filled with random records above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-foster",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# common configuration used for both tables\n",
    "table_config_template = {\n",
    "  \"tableName\": \"\",\n",
    "  \"tableType\": \"REALTIME\",\n",
    "  \"segmentsConfig\": {\n",
    "    \"timeColumnName\": \"trip_start_time_millis\",\n",
    "    \"timeType\": \"MILLISECONDS\",\n",
    "    \"retentionTimeUnit\": \"DAYS\",\n",
    "    \"retentionTimeValue\": \"60\",\n",
    "    \"schemaName\": \"trips\",\n",
    "  },\n",
    "  \"tenants\": {},\n",
    "  \"tableIndexConfig\": {\n",
    "    \"loadMode\": \"MMAP\",\n",
    "    \"invertedIndexColumns\": [\n",
    "        \"rider_name\",\n",
    "        \"driver_name\",\n",
    "        \"start_location\",\n",
    "        \"end_location\"\n",
    "    ],\n",
    "    \"streamConfigs\": {\n",
    "      \"streamType\": \"kafka\",\n",
    "      \"stream.kafka.topic.name\": \"trips\",\n",
    "      \"stream.kafka.consumer.type\": \"simple\",\n",
    "      \"stream.kafka.decoder.class.name\": \"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\",\n",
    "      \"stream.kafka.consumer.factory.class.name\": \"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\",\n",
    "      \"stream.kafka.zk.broker.url\": \"pinot-kafka-zookeeper:2181\",\n",
    "      \"stream.kafka.broker.list\": \"pinot-kafka:9092\",\n",
    "      \"stream.kafka.consumer.prop.auto.offset.reset\": \"smallest\"\n",
    "    }\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"customConfigs\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-terror",
   "metadata": {},
   "source": [
    "Pinot servers will continuously read from the Kafka topic into memory and compile a segment until a configured threshold is reached. The first table is configured to flush the new in-memory segment to disk, once either 12 hours have passed or the segment contains 80,000 rows (which will be the case for our example, as the data is already waiting in the Kafka stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create first table\n",
    "table_config = copy.deepcopy(table_config_template)\n",
    "table_config[\"tableName\"] = \"trips_segmentation_1\"\n",
    "table_config[\"segmentsConfig\"][\"replication\"] = \"1\"\n",
    "table_config[\"segmentsConfig\"][\"replicasPerPartition\"] = \"1\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.time\"] = \"12h\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.size\"] = \"80000\"\n",
    "display(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freelance-oklahoma",
   "metadata": {},
   "source": [
    "In contrast to the first table, the second one will target a segment size of 50,000 rows and will additionally create 3 replicas of each segment on different server instances for data availability (fault tolerance) and load distribution of queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create second table\n",
    "table_config = copy.deepcopy(table_config_template)\n",
    "table_config[\"tableName\"] = \"trips_segmentation_2\"\n",
    "table_config[\"segmentsConfig\"][\"replication\"] = \"3\"\n",
    "table_config[\"segmentsConfig\"][\"replicasPerPartition\"] = \"3\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.time\"] = \"12h\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"][\"realtime.segment.flush.threshold.size\"] = \"50000\"\n",
    "display(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-distinction",
   "metadata": {},
   "source": [
    "Let's wait for the tables to finish loading the data from Kafka:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-tulsa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_table_to_finish_loading(\"trips_segmentation_1\")\n",
    "wait_for_table_to_finish_loading(\"trips_segmentation_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-circus",
   "metadata": {},
   "source": [
    "The controller stores metadata for each segment, which can be viewed via its REST API. Each segment's metadata contains general information such as the table type, table name and time unit as well as segment-specific information such as the number of records (`segment.total.docs`), the timestamp of the segment's first and last record (`segment.start.time`, `segment.end.time`) and the segment's status (`segment.realtime.status`).\n",
    "New realtime segments start in status `IN_PROGRESS`, which means that the segment is currently consuming data from the Kafka topic. Once the size or time threshold is reached, the consuming servers start a segment commit protocol in order to agree on the last record that shall be included in the segment. Once the commit protocol is completed, the segment transitions to `DONE` and the servers flush the data to disk. Afterwards, a new segment is started again to consume further data from the event stream.\n",
    "\n",
    "We can now query the controller's REST API to retrieve metadata for all segments in both our tables.\n",
    "The first table contains less segments, but each segment contains a higher number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_metadata_1 = segment_metadata_for_table(\"trips_segmentation_1\")\n",
    "pd.DataFrame(segment_metadata_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-messaging",
   "metadata": {},
   "source": [
    "The segment metadata for the second table shows more segments. Each of them has a lower number of total records and 3 replicas (`segment.realtime.numReplicas`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_metadata_2 = segment_metadata_for_table(\"trips_segmentation_2\")\n",
    "pd.DataFrame(segment_metadata_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-guide",
   "metadata": {},
   "source": [
    "Pinot brokers are responsible for executing queries against the database. When a broker receives a new query, it sends multiple subqueries to Pinot servers that are hosting the segments belonging to the queried table. Once it has received results from all queried servers, it merges the subresults and returns the aggregated result to the client.\n",
    "In order to efficiently execute queries, brokers use segment metadata to figure out, which segments need to be queried. For example, if we want to list the top 5 drivers in terms of trips count in a given timeframe, only the segments hosting data of the timeframe need to be queried.\n",
    "\n",
    "To demonstrate this behaviour, we call the broker's REST API and query data from the time range of the first segment (before start time of the second segment). In the returned query statistics we can see, that not all segments of the table (`numSegmentsQueried`) are actually processed, but only 2 of them (`numSegmentsMatched`). This is because the last (the consuming) segment is always queried, as the metadata is not yet completed and so the broker can't tell upfront, if the last segment might contain relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-reform",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from first segment (consuming segment is always queried because of uncompleted metadata)\n",
    "query_for_trips_segmentation_1 = f\"\"\"\n",
    "    SELECT driver_name, sum(count) AS trips_count\n",
    "    FROM trips_segmentation_1\n",
    "    WHERE trip_start_time_millis BETWEEN {start_time_of_nth_segment(segment_metadata_1, 0)} AND {int(start_time_of_nth_segment(segment_metadata_1, 1))-1}\n",
    "    GROUP BY driver_name\n",
    "    ORDER BY trips_count desc\n",
    "    LIMIT 5\"\"\"\n",
    "\n",
    "query_result = query_sql(query_for_trips_segmentation_1)\n",
    "display(query_result_to_dataframe(query_result))\n",
    "display(extract_query_statistics_from_result_dataframe(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-tuning",
   "metadata": {},
   "source": [
    "The second query targets the second table and lists the top 5 drivers according to rating over the time range of the first 3 segments.\n",
    "Similarly to the query above, only relevant segments need to be processed for this query.\n",
    "However, in contrast to the first query execution, the broker can make use of the segment replication and can distribute the subqueries for individual segments across different servers (note that `numServersQueried` is now 3 instead of 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from first 3 segments (consuming segment is always queried because of uncompleted metadata)\n",
    "query_for_trips_segmentation_2 = f\"\"\"\n",
    "    SELECT driver_name, avg(driver_rating) AS rating\n",
    "    FROM trips_segmentation_2\n",
    "    WHERE trip_start_time_millis BETWEEN {start_time_of_nth_segment(segment_metadata_2, 0)} AND {int(start_time_of_nth_segment(segment_metadata_2, 3))-1}\n",
    "    GROUP BY driver_name\n",
    "    ORDER BY rating desc\n",
    "    LIMIT 5\"\"\"\n",
    "\n",
    "query_result = query_sql(query_for_trips_segmentation_2)\n",
    "display(query_result_to_dataframe(query_result))\n",
    "display(extract_query_statistics_from_result_dataframe(query_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-cocktail",
   "metadata": {},
   "source": [
    "## Query Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-integrity",
   "metadata": {},
   "source": [
    "In order to efficiently distribute queries across the fleet of servers, brokers maintain so called routing tables, which contain mappings between segments of a table and servers where they are hosted on. \n",
    "In case of replicated segments (like in the second table), the routing table contains entries for all servers hosting a single segment. When queries arrive at the broker, the routing tables and segment metadata allow to efficiently scatter queries across servers to balance load across the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-thanksgiving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpers for the upcoming examples\n",
    "def routing_table_for_query(query):\n",
    "    print(\"query: \" + query)\n",
    "    return requests.get('http://pinot-broker.pinot:8099/debug/routingTable/sql', params={\n",
    "        \"query\" : query\n",
    "    }).json()\n",
    "\n",
    "def routing_table_for_table(table):\n",
    "    return requests.get(f'http://pinot-broker.pinot:8099/debug/routingTable/{table}').json()\n",
    "\n",
    "def external_view_for_table(table):\n",
    "    return requests.get(f'http://pinot-controller.pinot:9000/tables/{table}/externalview').json()\n",
    "\n",
    "def routing_table_for_query_dataframe(query):\n",
    "    rt = routing_table_for_query(query)\n",
    "    rt_data = {}\n",
    "\n",
    "    for server, server_segments in rt.items():\n",
    "        server_name = server_name_from_instance(server)\n",
    "        for s in server_segments:\n",
    "            rt_data[s] = server_name\n",
    "\n",
    "    rt_data_list = []\n",
    "    for segment, server in rt_data.items():\n",
    "        rt_data_list.append({\"segment\": segment, \"server\": server})\n",
    "\n",
    "    rt_data_list.sort(key=lambda L: (int(ordinal_pattern.search(L[\"segment\"]).group(1)), L))\n",
    "    return pd.DataFrame(rt_data_list)\n",
    "\n",
    "def routing_table_for_table_dataframe(table):\n",
    "    rt = routing_table_for_table(table)\n",
    "    rt_data = {}\n",
    "\n",
    "    for table_name_type, table_rt in rt.items():\n",
    "        table_type = re.search('REALTIME|OFFLINE', table_name_type).group()\n",
    "        for server, server_segments in table_rt.items():\n",
    "            server_name = server_name_from_instance(server)\n",
    "            for s in server_segments:\n",
    "                try:\n",
    "                    rt_data[s][table_type] = server_name\n",
    "                except KeyError:\n",
    "                    rt_data[s] = {table_type: server_name}\n",
    "\n",
    "    rt_data_list = []\n",
    "    for segment, type_server in rt_data.items():\n",
    "        segment_data = {\"segment\": segment}\n",
    "        for table_type, server in type_server.items():\n",
    "            segment_data[table_type] = server\n",
    "        rt_data_list.append(segment_data)\n",
    "\n",
    "    rt_data_list.sort(key=lambda L: (int(ordinal_pattern.search(L[\"segment\"]).group(1)), L))\n",
    "    return pd.DataFrame(rt_data_list)\n",
    "\n",
    "def external_view_for_table_dataframe(table):\n",
    "    ev = external_view_for_table(table)\n",
    "    ev_data = {}\n",
    "\n",
    "    for table_type, ev_per_type in ev.items():\n",
    "        if ev_per_type == None:\n",
    "            continue\n",
    "        \n",
    "        for segment, segment_servers in ev_per_type.items():\n",
    "            if not segment in ev_data:\n",
    "                ev_data[segment] = {}\n",
    "            for server, state in segment_servers.items():\n",
    "                server_name = server_name_from_instance(server)\n",
    "                try:\n",
    "                    ev_data[segment][table_type].append(server_name)\n",
    "                except KeyError:\n",
    "                    ev_data[segment][table_type] = [server_name]\n",
    "\n",
    "    return pd.DataFrame(ev_data).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abroad-census",
   "metadata": {},
   "source": [
    "First, let's take a look at the external view for both tables. The external view shows an overview, which segments are available on which server. In case of the first table, each segment is only available on a single server. The second table has a replica of each segment on every server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessory-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(external_view_for_table_dataframe(\"trips_segmentation_1\"))\n",
    "display(external_view_for_table_dataframe(\"trips_segmentation_2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-choice",
   "metadata": {},
   "source": [
    "We can use the broker's debug endpoint to retrieve a routing table for a specific SQL query. This can be seen as a query execution plan for segments distributed across multiple servers. Similar to calculating an efficient query execution plan in classical RDBMSs, Pinot takes a look at metadata, statistics and server associations.\n",
    "The routing table might change everytime an identical query is executed, as brokers try to distribute compute load across servers hosting the same segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_table_for_query_dataframe(query_for_trips_segmentation_1.replace(\"trips_segmentation_1\", \"trips_segmentation_1_REALTIME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-blues",
   "metadata": {},
   "source": [
    "For the second query, the routing table shows, that the broker will try to equally distribute load between all the servers, as the segments are replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "routing_table_for_query_dataframe(query_for_trips_segmentation_2.replace(\"trips_segmentation_2\", \"trips_segmentation_2_REALTIME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-interpretation",
   "metadata": {},
   "source": [
    "## Advanced Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-beauty",
   "metadata": {},
   "source": [
    "The presented tables are rather simple and just demonstrate the basic mechanisms of segmentation, replication and query routing in Pinot. However, Pinot offers much more advanced configuration options for tweaking segment replication, availability and placement in large-scale Pinot clusters.\n",
    "\n",
    "For example, Pinot servers can be grouped in so called \"replica groups\", that can be spread across different availability zones. Segment replicas will then be assigned to servers in different replica groups in order to achieve high-availability setups. Furthermore, segments can be partitioned based on column values to further increase query performance by decreasing the number of segments that need to be processed for a given query. This is very similar to partitioning/sharding in typical RDBMSs.\n",
    "Additionally, servers can be assigned to different tenants for sharing a cluster across teams or grouped into server-pools to achieve no-downtime rolling restarts of large clusters.\n",
    "\n",
    "All of these options show, that segmentation in Pinot is in the simplest aspects quite comparable to sharding mechanism in other database systems, but it is also much more advanced to support large-scale analytical use-cases while maintaining high performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-supply",
   "metadata": {},
   "source": [
    "# Batch Ingestion and Hybrid Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-overhead",
   "metadata": {},
   "source": [
    "As mentioned earlier, Pinot also support ingesting data from batch processing jobs. For offline tables, the same principles apply as for realtime tables with regards to segmentation and query routing. \n",
    "Though, segments are compiled and packaged outside Pinot. For this purpose, Pinot offers different mechanisms to load pre-built segments from object stores (such as S3) or HDFS or to build new segments using Hadoop and/or Spark.\n",
    "Segments are packaged as gzipped tar-archives (including data, index maps, column statistics) and can be uploaded to and downloaded from the controller.\n",
    "\n",
    "While offline tables can be used standalone similar to the realtime tables presented above, a more interesting option is to combine an offline and a realtime table to form a hybrid table.\n",
    "Hybrid tables are comprised of two individual tables, one offline table and one hybrid table, both sharing the same name, schema and – most importantly – time column. The hybrid table can be queried just like any other table, but the broker will transparently rewrite queries to fetch older records from the offline table and newer records from the realtime table.\n",
    "This allows to process, deduplicate and sanitize records before pushing them to long-term storage. This is a key differentiator between Pinot and other databases and OLAP stores. It allows Pinot to achieve high-throughput ingestion, low-latency realtime analytics, while still allowing to backfill data in batch processing.\n",
    "\n",
    "Since version `0.6.0` Pinot also offers a mechanism to regularly move records from a realtime table to the corresponding offline table. To configure this, the user can schedule a task, which should be executed on a minion instance for example once every day. The task execution will then take over downloading, transforming, aggregating, sorting and uploading of segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-complaint",
   "metadata": {},
   "source": [
    "To demonstrate how batch ingestion and hybrid tables work in Pinot without setting up an external batch processing system or periodic segment transformation job, we're going to create a realtime table reading from our Kafka `trips` topic, download completed segments from the controller and re-upload them as offline segments.\n",
    "\n",
    "First, we need to create both tables (note the shared name and schema):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common configuration used for both tables types\n",
    "table_config_template = {\n",
    "  \"tableName\": \"trips_hybrid\",\n",
    "  \"segmentsConfig\": {\n",
    "    \"timeColumnName\": \"trip_start_time_millis\",\n",
    "    \"timeType\": \"MILLISECONDS\",\n",
    "    \"retentionTimeUnit\": \"DAYS\",\n",
    "    \"retentionTimeValue\": \"60\",\n",
    "    \"schemaName\": \"trips\",\n",
    "    \"replication\": \"1\"\n",
    "  },\n",
    "  \"tenants\": {},\n",
    "  \"tableIndexConfig\": {\n",
    "    \"loadMode\": \"MMAP\",\n",
    "    \"invertedIndexColumns\": [\n",
    "        \"rider_name\",\n",
    "        \"driver_name\",\n",
    "        \"start_location\",\n",
    "        \"end_location\"\n",
    "    ]\n",
    "  },\n",
    "  \"metadata\": {\n",
    "    \"customConfigs\": {}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-honor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create offline table\n",
    "table_config = copy.deepcopy(table_config_template)\n",
    "table_config[\"tableType\"] = \"OFFLINE\"\n",
    "print(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create realtime table\n",
    "table_config[\"tableType\"] = \"REALTIME\"\n",
    "table_config[\"segmentsConfig\"][\"replicasPerPartition\"] = \"1\"\n",
    "table_config[\"tableIndexConfig\"][\"streamConfigs\"] = {\n",
    "  \"streamType\": \"kafka\",\n",
    "  \"stream.kafka.consumer.type\": \"simple\",\n",
    "  \"stream.kafka.topic.name\": \"trips\",\n",
    "  \"stream.kafka.decoder.class.name\": \"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder\",\n",
    "  \"stream.kafka.consumer.factory.class.name\": \"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory\",\n",
    "  \"stream.kafka.zk.broker.url\": \"pinot-kafka-zookeeper:2181\",\n",
    "  \"stream.kafka.broker.list\": \"pinot-kafka:9092\",\n",
    "  \"realtime.segment.flush.threshold.time\": \"12h\",\n",
    "  \"realtime.segment.flush.threshold.size\": \"50000\",\n",
    "  \"stream.kafka.consumer.prop.auto.offset.reset\": \"smallest\"\n",
    "}\n",
    "print(requests.post('http://pinot-controller.pinot:9000/tables', json=table_config).json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-bishop",
   "metadata": {},
   "source": [
    "Let's again wait for our table to finish loading the data from Kafka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_table_to_finish_loading(\"trips_hybrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-november",
   "metadata": {},
   "source": [
    "Let's take a look at the external view of the hybrid table before touching it. We can see some realtime segments, that were built from the data stream from Kafka, but there are no offline segments so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_view_for_table_dataframe(\"trips_hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers for transforming realtime segments to offline segment\n",
    "tmp_hybrid_basedir = \"/tmp/trips_hybrid\"\n",
    "# cleanup old artifacts if any\n",
    "shutil.rmtree(tmp_hybrid_basedir, ignore_errors=True)\n",
    "os.mkdir(tmp_hybrid_basedir)\n",
    "\n",
    "def path_for_realtime_tar(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}.tar.gz\"\n",
    "\n",
    "def path_for_offline_dir(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}_offline\"\n",
    "\n",
    "def path_for_offline_tar(segment_name):\n",
    "    return f\"{tmp_hybrid_basedir}/{segment_name}_offline.tar.gz\"\n",
    "\n",
    "def download_segment(segment_metadata):\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    download_url = segment_metadata[\"segment.realtime.download.url\"]\n",
    "    segment_realtime_tar = path_for_realtime_tar(segment_name)\n",
    "\n",
    "    # cleanup old downloads\n",
    "    try:\n",
    "        os.remove(segment_realtime_tar)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "    # download realtime segment tar\n",
    "    response = requests.get(download_url, stream=True)\n",
    "    with open(segment_realtime_tar, 'wb') as out_file:\n",
    "        shutil.copyfileobj(response.raw, out_file)\n",
    "    del response\n",
    "    \n",
    "    print(f\"segment {segment_name} downloaded from {download_url} to {segment_realtime_tar}\")\n",
    "    return segment_realtime_tar\n",
    "\n",
    "def untar_segment(segment_metadata):\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_basedir = path_for_offline_dir(segment_name)\n",
    "    segment_realtime_tar = path_for_realtime_tar(segment_name)\n",
    "\n",
    "    # cleanup old artifacts if any\n",
    "    shutil.rmtree(segment_offline_basedir, ignore_errors=True)\n",
    "\n",
    "    # extract downloaded segment tar\n",
    "    with tarfile.open(segment_realtime_tar, 'r:gz') as tar:\n",
    "        tar.extractall(path=segment_offline_basedir)\n",
    "\n",
    "    print(f\"segment {segment_name} untarred to {segment_offline_basedir}\")\n",
    "    return segment_offline_basedir\n",
    "\n",
    "def transform_segment(segment_metadata):\n",
    "    realtime_table_name = segment_metadata[\"segment.table.name\"]\n",
    "    offline_table_name = realtime_table_name.replace(\"REALTIME\", \"OFFLINE\")\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_basedir = path_for_offline_dir(segment_name)\n",
    "    \n",
    "    # modify metadata.properties of segment\n",
    "    segment_offline_dir = segment_offline_basedir + \"/\" + segment_name\n",
    "    metadata_file = segment_offline_dir + \"/v3/metadata.properties\"\n",
    "    metadata_contents = None\n",
    "    with open(metadata_file, 'r') as file:\n",
    "      metadata_contents = file.read()\n",
    "    \n",
    "    metadata_contents = metadata_contents.replace(realtime_table_name, offline_table_name)\n",
    "    \n",
    "    with open(metadata_file, 'w') as file:\n",
    "      file.write(metadata_contents)\n",
    "    del metadata_contents\n",
    "\n",
    "    # create new offline segment tar\n",
    "    segment_offline_tar = path_for_offline_tar(segment_name)\n",
    "    with tarfile.open(segment_offline_tar, 'w:gz') as tar:\n",
    "        tar.add(segment_offline_dir, arcname=segment_name)\n",
    "\n",
    "    print(f\"segment {segment_name} transformed to offline segment to {segment_offline_tar}\")\n",
    "    return segment_offline_tar\n",
    "\n",
    "def upload_segment_to_offline_table(segment_metadata):\n",
    "    realtime_table_name = segment_metadata[\"segment.table.name\"]\n",
    "    segment_name = segment_metadata[\"segment.name\"]\n",
    "    segment_offline_tar = path_for_offline_tar(segment_name)\n",
    "    table_name = realtime_table_name.replace(\"_REALTIME\", \"_OFFLINE\")\n",
    "    \n",
    "    # POST segment as multipart/form-data for key 'segment'\n",
    "    with open(segment_offline_tar, 'rb') as tar:\n",
    "        response = requests.post(f'http://pinot-controller.pinot:9000/v2/segments?table={table_name}', files={\n",
    "            'segment': tar\n",
    "        })\n",
    "        print(response)\n",
    "        print(response.json())\n",
    "\n",
    "def transform_and_upload_nth_segment_to_offline_table(segment_metadata, n):\n",
    "    nth_meta = segment_metadata_of_nth_segment(segment_metadata, n, table_type=\"REALTIME\")\n",
    "    \n",
    "    # download, transform and upload all in one row\n",
    "    download_segment(nth_meta)\n",
    "    untar_segment(nth_meta)\n",
    "    transform_segment(nth_meta)\n",
    "    upload_segment_to_offline_table(nth_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-piece",
   "metadata": {},
   "source": [
    "Now, we fetch the first two segments from the controller, manipulate the metadata and re-upload them to the controller as offline segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_metadata_hybrid = segment_metadata_for_table(\"trips_hybrid\")\n",
    "\n",
    "transform_and_upload_nth_segment_to_offline_table(segment_metadata_hybrid, 0)\n",
    "transform_and_upload_nth_segment_to_offline_table(segment_metadata_hybrid, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-filename",
   "metadata": {},
   "source": [
    "The external view for our hybrid table now shows the newly added offline segments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_view_for_table_dataframe(\"trips_hybrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-bahamas",
   "metadata": {},
   "source": [
    "This example query lists the top 5 riders in terms of total trip time. It shows that hybrid tables can be queried in the exact same way, as realtime tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_for_hybrid = \"\"\"\n",
    "    SELECT rider_name, sum(trip_end_time_millis - trip_start_time_millis) / (60*60*1000) AS trip_time_sum\n",
    "    FROM trips_hybrid\n",
    "    GROUP BY rider_name\n",
    "    ORDER BY trip_time_sum DESC\n",
    "    LIMIT 5\n",
    "    \"\"\"\n",
    "\n",
    "query_result = query_sql(query_for_hybrid)\n",
    "query_result_to_dataframe(query_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
